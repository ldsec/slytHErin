{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crypto_nets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CryptoNet implementation and training on MNIST dataset"
      ],
      "metadata": {
        "id": "HYmdRutcpdeR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "prOXZ9RESeYD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.utils import save_image\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "DUluBfyZuKld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## DUMMY MODEL\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()        \n",
        "        self.conv1 = nn.Sequential(         \n",
        "            nn.Conv2d(\n",
        "                in_channels=1,              \n",
        "                out_channels=16,            \n",
        "                kernel_size=5,              \n",
        "                stride=1,                   \n",
        "                padding=2,                  \n",
        "            ),                              \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(kernel_size=2),    \n",
        "        )\n",
        "        self.conv2 = nn.Sequential(         \n",
        "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
        "            nn.ReLU(),                      \n",
        "            nn.MaxPool2d(2),                \n",
        "        )        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear(32 * 7 * 7, 10)    \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "        x = x.view(x.size(0), -1)       \n",
        "        output = self.out(x)\n",
        "        return output  # return x for visualization"
      ],
      "metadata": {
        "id": "Ii4rDPKqVPYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaledAvgPool2d(nn.Module):\n",
        "    \"\"\"Define the ScaledAvgPool layer, a.k.a the Sum Pool\"\"\"\n",
        "    def __init__(self,kernel_size):\n",
        "      super().__init__()\n",
        "      self.kernel_size = kernel_size\n",
        "      self.AvgPool = nn.AvgPool2d(kernel_size=self.kernel_size, stride=1, padding=1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "      return (self.kernel_size**2)*self.AvgPool(x)\n",
        "\n",
        "class CryptoNet(nn.Module):\n",
        "  '''\n",
        "    TO DO: check how in the paper the avg pool does not downscale the input size...weird padding?\n",
        "    EDIT: probably yes, it's a same convolution\n",
        "  '''\n",
        "  def __init__(self, verbose):\n",
        "    super().__init__()\n",
        "    self.verbose = verbose\n",
        "    self.pad = F.pad\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=5, stride=2)\n",
        "    self.square1 = torch.square\n",
        "    self.scaledAvgPool1 = ScaledAvgPool2d(kernel_size=3)\n",
        "    self.conv2 = nn.Conv2d(in_channels=5, out_channels=50, kernel_size=5, stride=2)\n",
        "    self.scaledAvgPool2 = ScaledAvgPool2d(kernel_size=3)\n",
        "    self.fc1 = nn.Linear(in_features=1250, out_features=100) # in paper in_features was 1250\n",
        "    self.square2 = torch.square\n",
        "    self.fc2 = nn.Linear(in_features=100, out_features=10)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pad(x, (1,0,1,0))\n",
        "    x = self.conv1(x)\n",
        "    x = self.square1(x)\n",
        "    x = self.scaledAvgPool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.scaledAvgPool2(x)\n",
        "    ## Flatten\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.square2(x)\n",
        "    if self.verbose:\n",
        "      print(\"Blow up? --> \",x.mean())\n",
        "    x = self.fc2(x)\n",
        "    if self.verbose:\n",
        "      print(\"Blow up? --> \",x.mean())\n",
        "    x = self.sigmoid(x)\n",
        "    return x\n",
        "\n",
        "  def weights_init(self):\n",
        "    \"\"\" Custom initilization to avoid square activation to blow up \"\"\"\n",
        "    for n,p in self.named_parameters():\n",
        "      if n == \"conv2\":\n",
        "        nn.init.uniform_(p.weight, 1e-10, 1e-9)\n",
        "      elif n == \"conv1\":\n",
        "        nn.init.uniform_(p.weight, 1e-10, 1e-9)\n",
        "      elif n == \"fc1\":\n",
        "        nn.init.uniform_(p.weight, 1e-10, 1e-9)\n",
        "      elif n == \"fc2\":\n",
        "        nn.init.uniform_(p.weight, 1e-10, 1e-9)\n"
      ],
      "metadata": {
        "id": "bGKsu0dNuGEH"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Datasets"
      ],
      "metadata": {
        "id": "7sX-7JDDtHOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataHandler():\n",
        "  def __init__(self, dataset : str):\n",
        "    if dataset == \"MNIST\":\n",
        "      transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "      train_ds = MNIST(\"data/\", train=True, download=True, transform=transform)\n",
        "      test_ds = MNIST(\"data/\", train=False, download=True)\n",
        "\n",
        "      self.train_dl = DataLoader(train_ds, batch_size = 512, shuffle=True, drop_last=True)\n",
        "      self.test_dl = DataLoader(test_ds, batch_size = 512, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "3zxoMQRRsF1o"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot gradient flow"
      ],
      "metadata": {
        "id": "xXXqZm508qA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_grad_flow(named_parameters):\n",
        "    ## From https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063\n",
        "    ## Beware it's a little bit tricky to interpret results\n",
        "    '''Plots the gradients flowing through different layers in the net during training.\n",
        "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
        "    \n",
        "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
        "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
        "\n",
        "    ave_grads = []\n",
        "    max_grads= []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        if(p.requires_grad) and (\"bias\" not in n):\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean())\n",
        "            max_grads.append(p.grad.abs().max())\n",
        "            print(f\"Layer {n}, grad avg {p.grad.mean()}\")\n",
        "    plt.bar(np.arange(len(max_grads)), max(max_grads), alpha=0.1, lw=1, color=\"c\")\n",
        "    plt.bar(np.arange(len(max_grads)), np.mean(ave_grads), alpha=0.1, lw=1, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
        "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "    plt.xlim(left=0, right=len(ave_grads))\n",
        "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient flow\")\n",
        "    plt.grid(True)\n",
        "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
        "                Line2D([0], [0], color=\"b\", lw=4),\n",
        "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
        "    \n"
      ],
      "metadata": {
        "id": "h3f19IYJ8nIQ"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "TuwFtAqgtLYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## setup torch enviro\n",
        "torch.manual_seed(9329582034)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "## init model\n",
        "model = CryptoNet(verbose=True)\n",
        "model.weights_init()\n",
        "model = model.to(device=device)\n",
        "\n",
        "dataHandler = DataHandler(\"MNIST\")\n",
        "\n",
        "## training params setup\n",
        "learning_rate = 3e-6\n",
        "momentum = 0.9\n",
        "num_epochs = 5\n",
        "total_step = len(dataHandler.train_dl)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (data, labels) in enumerate(dataHandler.train_dl):\n",
        "    data = data.to(device=device)\n",
        "    labels = labels.to(device=device)\n",
        "    #labels = labels.to(torch.float32)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(data)\n",
        "    loss = criterion(predictions, labels)\n",
        "    loss.backward()\n",
        "    if model.verbose:\n",
        "      print(f\"[?] Step {i+1} Epoch {epoch+1}\")\n",
        "      plot_grad_flow(model.named_parameters())\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 10 == 0:\n",
        "      print ('[!] Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "\n",
        "torch.save(model, \"cryptoNet.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xnkgcAJktEu9",
        "outputId": "7cca5067-be08-4135-c021-abc89c13500b"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blow up? -->  tensor(277.3840, grad_fn=<MeanBackward0>)\n",
            "Blow up? -->  tensor(-71.3225, grad_fn=<MeanBackward0>)\n",
            "[?] Step 1 Epoch 1\n",
            "Layer conv1.weight, grad avg 0.0872945711016655\n",
            "Layer conv2.weight, grad avg 0.002221754053607583\n",
            "Layer fc1.weight, grad avg -3.2166382879950106e-05\n",
            "Layer fc2.weight, grad avg -0.0024755375925451517\n",
            "Blow up? -->  tensor(263.3083, grad_fn=<MeanBackward0>)\n",
            "Blow up? -->  tensor(-67.6206, grad_fn=<MeanBackward0>)\n",
            "[?] Step 2 Epoch 1\n",
            "Layer conv1.weight, grad avg 0.0795922726392746\n",
            "Layer conv2.weight, grad avg -0.007514803670346737\n",
            "Layer fc1.weight, grad avg -0.0001461879292037338\n",
            "Layer fc2.weight, grad avg -0.0042764414101839066\n",
            "Blow up? -->  tensor(276.8299, grad_fn=<MeanBackward0>)\n",
            "Blow up? -->  tensor(-72.7043, grad_fn=<MeanBackward0>)\n",
            "[?] Step 3 Epoch 1\n",
            "Layer conv1.weight, grad avg 0.07990657538175583\n",
            "Layer conv2.weight, grad avg -0.008509754203259945\n",
            "Layer fc1.weight, grad avg -0.0001442738139303401\n",
            "Layer fc2.weight, grad avg -0.02101033367216587\n",
            "Blow up? -->  tensor(284.3843, grad_fn=<MeanBackward0>)\n",
            "Blow up? -->  tensor(-74.4724, grad_fn=<MeanBackward0>)\n",
            "[?] Step 4 Epoch 1\n",
            "Layer conv1.weight, grad avg 0.07621917873620987\n",
            "Layer conv2.weight, grad avg 0.0015796843217685819\n",
            "Layer fc1.weight, grad avg -9.85189835773781e-05\n",
            "Layer fc2.weight, grad avg -0.0040257778018713\n",
            "Blow up? -->  tensor(281.4503, grad_fn=<MeanBackward0>)\n",
            "Blow up? -->  tensor(-71.5415, grad_fn=<MeanBackward0>)\n",
            "[?] Step 5 Epoch 1\n",
            "Layer conv1.weight, grad avg 0.0650566816329956\n",
            "Layer conv2.weight, grad avg -0.0130112674087286\n",
            "Layer fc1.weight, grad avg -0.00021326464775484055\n",
            "Layer fc2.weight, grad avg -0.012608285993337631\n",
            "Blow up? -->  tensor(270.5022, grad_fn=<MeanBackward0>)\n",
            "Blow up? -->  tensor(-66.4205, grad_fn=<MeanBackward0>)\n",
            "[?] Step 6 Epoch 1\n",
            "Layer conv1.weight, grad avg -0.021373402327299118\n",
            "Layer conv2.weight, grad avg 0.001472603646107018\n",
            "Layer fc1.weight, grad avg -8.514152432326227e-05\n",
            "Layer fc2.weight, grad avg -0.01365173701196909\n",
            "Blow up? -->  tensor(287.0551, grad_fn=<MeanBackward0>)\n",
            "Blow up? -->  tensor(-76.4904, grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-218-f836127c7b17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[?] Step {i+1} Epoch {epoch+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "lz5pM3GavjgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = CNN()\n",
        "\n",
        "def grad_clipping(model):\n",
        "  for p in model.parameters():\n",
        "    p.register_hook(lambda grad: print(grad))\n",
        "    p.register_hook(lambda grad: torch.clamp(grad, 0, 1.0))\n",
        "\n",
        "    p.register_hook(lambda grad: print(f\"{p} -> {grad}\"))\n",
        "\n",
        "#grad_clipping(model)\n",
        "model = model.to(device=device)\n",
        "dataHandler = DataHandler(\"MNIST\")\n",
        "\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "num_epochs = 1\n",
        "total_step = len(dataHandler.train_dl)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (data, labels) in enumerate(dataHandler.train_dl):\n",
        "    data = data.to(device=device)\n",
        "    labels = labels.to(device=device)\n",
        "    #labels = labels.to(torch.float32)\n",
        "\n",
        "    ## Forward\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(data)\n",
        "    loss = criterion(predictions, labels)\n",
        "    loss.backward()\n",
        "    plot_grad_flow(model.named_parameters())\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "torch.save(model, \"cryptoNet.pt\")"
      ],
      "metadata": {
        "id": "uD7LT4QNvkaJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d46c1a6-e6cd-46f1-cd85-f4ac5cc39dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0055), tensor(0.0038), tensor(0.0065)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0054), tensor(0.0037), tensor(0.0060)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0063), tensor(0.0039), tensor(0.0060)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0080), tensor(0.0043), tensor(0.0066)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0090), tensor(0.0047), tensor(0.0065)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0138), tensor(0.0054), tensor(0.0082)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0172), tensor(0.0060), tensor(0.0076)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0229), tensor(0.0062), tensor(0.0079)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0239), tensor(0.0062), tensor(0.0082)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0258), tensor(0.0066), tensor(0.0108)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0271), tensor(0.0063), tensor(0.0107)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0260), tensor(0.0069), tensor(0.0166)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0299), tensor(0.0067), tensor(0.0149)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0284), tensor(0.0062), tensor(0.0144)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0300), tensor(0.0063), tensor(0.0134)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0291), tensor(0.0064), tensor(0.0156)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0251), tensor(0.0047), tensor(0.0108)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0219), tensor(0.0046), tensor(0.0144)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0174), tensor(0.0043), tensor(0.0142)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0199), tensor(0.0052), tensor(0.0150)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0149), tensor(0.0039), tensor(0.0147)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0131), tensor(0.0042), tensor(0.0168)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0168), tensor(0.0050), tensor(0.0189)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0075), tensor(0.0043), tensor(0.0186)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0152), tensor(0.0045), tensor(0.0180)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0098), tensor(0.0040), tensor(0.0157)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0139), tensor(0.0059), tensor(0.0222)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0093), tensor(0.0049), tensor(0.0220)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0104), tensor(0.0035), tensor(0.0146)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0103), tensor(0.0042), tensor(0.0175)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0099), tensor(0.0044), tensor(0.0201)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0087), tensor(0.0041), tensor(0.0198)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0127), tensor(0.0046), tensor(0.0162)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0069), tensor(0.0035), tensor(0.0152)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0089), tensor(0.0040), tensor(0.0146)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0079), tensor(0.0042), tensor(0.0170)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0148), tensor(0.0053), tensor(0.0198)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0123), tensor(0.0055), tensor(0.0160)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0090), tensor(0.0039), tensor(0.0131)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0069), tensor(0.0036), tensor(0.0165)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0067), tensor(0.0031), tensor(0.0126)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0058), tensor(0.0029), tensor(0.0116)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0077), tensor(0.0027), tensor(0.0100)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0119), tensor(0.0056), tensor(0.0176)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0066), tensor(0.0031), tensor(0.0115)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0088), tensor(0.0027), tensor(0.0112)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0079), tensor(0.0033), tensor(0.0146)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0066), tensor(0.0033), tensor(0.0128)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0084), tensor(0.0034), tensor(0.0149)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0079), tensor(0.0033), tensor(0.0143)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0090), tensor(0.0035), tensor(0.0122)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0119), tensor(0.0043), tensor(0.0140)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0054), tensor(0.0028), tensor(0.0089)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0093), tensor(0.0039), tensor(0.0161)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0150), tensor(0.0074), tensor(0.0212)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0098), tensor(0.0049), tensor(0.0193)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0084), tensor(0.0033), tensor(0.0100)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0108), tensor(0.0032), tensor(0.0142)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0087), tensor(0.0029), tensor(0.0090)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0060), tensor(0.0028), tensor(0.0110)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0083), tensor(0.0034), tensor(0.0122)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0128), tensor(0.0060), tensor(0.0157)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0123), tensor(0.0052), tensor(0.0157)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0078), tensor(0.0038), tensor(0.0143)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0070), tensor(0.0031), tensor(0.0109)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0059), tensor(0.0044), tensor(0.0180)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0053), tensor(0.0029), tensor(0.0110)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0067), tensor(0.0029), tensor(0.0080)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0142), tensor(0.0063), tensor(0.0156)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0078), tensor(0.0038), tensor(0.0118)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0112), tensor(0.0044), tensor(0.0137)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0083), tensor(0.0033), tensor(0.0093)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0136), tensor(0.0050), tensor(0.0124)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0133), tensor(0.0050), tensor(0.0132)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0066), tensor(0.0025), tensor(0.0081)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0080), tensor(0.0036), tensor(0.0139)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0103), tensor(0.0044), tensor(0.0142)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0085), tensor(0.0037), tensor(0.0107)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0063), tensor(0.0024), tensor(0.0083)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0055), tensor(0.0026), tensor(0.0064)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0062), tensor(0.0029), tensor(0.0074)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0166), tensor(0.0053), tensor(0.0127)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0072), tensor(0.0030), tensor(0.0085)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0091), tensor(0.0036), tensor(0.0097)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0062), tensor(0.0038), tensor(0.0118)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0079), tensor(0.0038), tensor(0.0133)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0092), tensor(0.0034), tensor(0.0090)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0076), tensor(0.0041), tensor(0.0139)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0078), tensor(0.0029), tensor(0.0085)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0086), tensor(0.0041), tensor(0.0103)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0061), tensor(0.0028), tensor(0.0091)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0063), tensor(0.0023), tensor(0.0070)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0065), tensor(0.0030), tensor(0.0080)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0121), tensor(0.0043), tensor(0.0090)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0053), tensor(0.0013), tensor(0.0043)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0058), tensor(0.0026), tensor(0.0069)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0055), tensor(0.0023), tensor(0.0061)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0063), tensor(0.0030), tensor(0.0135)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0048), tensor(0.0021), tensor(0.0086)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0073), tensor(0.0035), tensor(0.0079)]\n",
            "Epoch [1/1], Step [100/468], Loss: 0.2237\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0058), tensor(0.0031), tensor(0.0102)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0075), tensor(0.0031), tensor(0.0098)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0064), tensor(0.0026), tensor(0.0101)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0069), tensor(0.0026), tensor(0.0078)]\n",
            "['conv1.0.weight', 'conv2.0.weight', 'out.weight']\n",
            "[tensor(0.0079), tensor(0.0031), tensor(0.0090)]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-1705c379236f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m## Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-29e930ea2d70>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# flatten the output of conv2 to (batch_size, 32 * 7 * 7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}