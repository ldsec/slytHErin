[!] Training Epoch 1, step 234 ==> loss 0.2504336204793718, accuracy 0.14544938568376067
[!] Training Epoch 2, step 234 ==> loss 0.2501196716076288, accuracy 0.16164196047008547
[!] Training Epoch 3, step 234 ==> loss 0.25007569929982865, accuracy 0.16713408119658119
[!] Training Epoch 4, step 234 ==> loss 0.25005554541563374, accuracy 0.1675347222222222
[!] Training Epoch 5, step 234 ==> loss 0.2500438634146992, accuracy 0.1674011752136752
[!] Training Epoch 6, step 234 ==> loss 0.25003621275098914, accuracy 0.1672676282051282
[!] Training Epoch 7, step 234 ==> loss 0.2500308176391145, accuracy 0.16691706730769232
[!] Training Epoch 8, step 234 ==> loss 0.2500267919057455, accuracy 0.16648303952991453
[!] Training Epoch 9, step 234 ==> loss 0.25002367972818196, accuracy 0.16523103632478633
[!] Training Epoch 10, step 234 ==> loss 0.2500212089373515, accuracy 0.1646300747863248
[!] Training Epoch 11, step 234 ==> loss 0.2500191912946538, accuracy 0.1638621794871795
[!] Training Epoch 12, step 234 ==> loss 0.2500175133220151, accuracy 0.1635783920940171
[!] Training Epoch 13, step 234 ==> loss 0.25001609911266554, accuracy 0.1621928418803419
[!] Training Epoch 14, step 234 ==> loss 0.2500148923733296, accuracy 0.16107438568376067
[!] Training Epoch 15, step 234 ==> loss 0.2500138505656495, accuracy 0.16067374465811965
[!] Training Epoch 16, step 234 ==> loss 0.2500129401938528, accuracy 0.1595219017094017
[!] Training Epoch 17, step 234 ==> loss 0.2500121404982021, accuracy 0.15875400641025642
[!] Training Epoch 18, step 234 ==> loss 0.25001142842647356, accuracy 0.158203125
[!] Training Epoch 19, step 234 ==> loss 0.25001079977577567, accuracy 0.15733506944444445
[!] Training Epoch 20, step 234 ==> loss 0.2500102293287587, accuracy 0.1567508012820513
[!] Training Epoch 21, step 234 ==> loss 0.25000971568445873, accuracy 0.15635016025641027
[!] Training Epoch 22, step 234 ==> loss 0.2500092492908494, accuracy 0.1556824252136752
[!] Training Epoch 23, step 234 ==> loss 0.2500088222515889, accuracy 0.1544971955128205
[!] Training Epoch 24, step 234 ==> loss 0.2500084386422084, accuracy 0.1535957532051282
[!] Training Epoch 25, step 234 ==> loss 0.25000807935865516, accuracy 0.15332865918803418
[!] Training Epoch 26, step 234 ==> loss 0.25000775140574855, accuracy 0.1519097222222222
[!] Training Epoch 27, step 234 ==> loss 0.2500074493069934, accuracy 0.15182625534188035
[!] Training Epoch 28, step 234 ==> loss 0.25000716847741705, accuracy 0.15122529380341881
[!] Training Epoch 29, step 234 ==> loss 0.25000690586037105, accuracy 0.15072449252136752
[!] Training Epoch 30, step 234 ==> loss 0.25000666247473824, accuracy 0.15002337072649571
[!] Training Epoch 31, step 234 ==> loss 0.2500064381931582, accuracy 0.14943910256410256
[!] Training Epoch 32, step 234 ==> loss 0.25000622244472176, accuracy 0.14945579594017094
[!] Training Epoch 33, step 234 ==> loss 0.25000602388993287, accuracy 0.14888822115384615
[!] Training Epoch 34, step 234 ==> loss 0.25000583679757565, accuracy 0.1485877403846154
[!] Training Epoch 35, step 234 ==> loss 0.25000566116765016, accuracy 0.14840411324786323
[!] Training Epoch 36, step 234 ==> loss 0.25000549458030963, accuracy 0.14797008547008547
[!] Training Epoch 37, step 234 ==> loss 0.25000533639875233, accuracy 0.14721888354700854
[!] Training Epoch 38, step 234 ==> loss 0.25000518827866286, accuracy 0.14701856303418803
[!] Training Epoch 39, step 234 ==> loss 0.2500050470360324, accuracy 0.14650106837606838
[!] Training Epoch 40, step 234 ==> loss 0.2500049140718248, accuracy 0.14596688034188035
[!] Training Epoch 41, step 234 ==> loss 0.25000478556522954, accuracy 0.14553285256410256
[!] Training Epoch 42, step 234 ==> loss 0.250004663808733, accuracy 0.14469818376068377
[!] Training Epoch 43, step 234 ==> loss 0.25000455033065927, accuracy 0.14453125
[!] Training Epoch 44, step 234 ==> loss 0.2500044402913151, accuracy 0.14428084935897437
[!] Training Epoch 45, step 234 ==> loss 0.25000433700206953, accuracy 0.14369658119658119
[!] Training Epoch 46, step 234 ==> loss 0.25000423651475173, accuracy 0.14282852564102563
[!] Training Epoch 47, step 234 ==> loss 0.2500041418860101, accuracy 0.14252804487179488
[!] Training Epoch 48, step 234 ==> loss 0.25000405095071876, accuracy 0.14234441773504272
[!] Training Epoch 49, step 234 ==> loss 0.25000396167111194, accuracy 0.14199385683760685
[!] Training Epoch 50, step 234 ==> loss 0.2500038776132796, accuracy 0.14147636217948717
[!] Training Epoch 51, step 234 ==> loss 0.2500037973762577, accuracy 0.14127604166666666
[!] Training Epoch 52, step 234 ==> loss 0.250003720068524, accuracy 0.14060830662393162
[!] Training Epoch 53, step 234 ==> loss 0.25000364505327666, accuracy 0.1401909722222222
[!] Training Epoch 54, step 234 ==> loss 0.2500035725852363, accuracy 0.14035790598290598
[!] Training Epoch 55, step 234 ==> loss 0.25000350495688933, accuracy 0.13990718482905984
[!] Training Epoch 56, step 234 ==> loss 0.2500034373285424, accuracy 0.13953993055555555
[!] Training Epoch 57, step 234 ==> loss 0.2500033742851681, accuracy 0.13912259615384615
[!] Training Epoch 58, step 234 ==> loss 0.2500033121333163, accuracy 0.13885550213675213
[!] Training Epoch 59, step 234 ==> loss 0.2500032532928336, accuracy 0.13877203525641027
[!] Training Epoch 60, step 234 ==> loss 0.25000319343346816, accuracy 0.1384548611111111
[!] Training Epoch 61, step 234 ==> loss 0.25000313905059784, accuracy 0.13840478098290598
[!] Training Epoch 62, step 234 ==> loss 0.2500030844130068, accuracy 0.13793736645299146
[!] Training Epoch 63, step 234 ==> loss 0.2500030327047038, accuracy 0.13768696581196582
[!] Training Epoch 64, step 234 ==> loss 0.25000298188792336, accuracy 0.13733640491452992
[!] Training Epoch 65, step 234 ==> loss 0.25000293438251203, accuracy 0.1368022168803419
[!] Training Epoch 66, step 234 ==> loss 0.2500028854761368, accuracy 0.13645165598290598
[!] Training Epoch 67, step 234 ==> loss 0.25000284293777925, accuracy 0.13605101495726496
[!] Training Epoch 68, step 234 ==> loss 0.2500027939040437, accuracy 0.13638488247863248
[!] Training Epoch 69, step 234 ==> loss 0.25000275302137065, accuracy 0.13571714743589744
[!] Training Epoch 70, step 234 ==> loss 0.2500027111198148, accuracy 0.13571714743589744
[!] Training Epoch 71, step 234 ==> loss 0.25000266909089863, accuracy 0.13506610576923078
[!] Training Epoch 72, step 234 ==> loss 0.25000262973654985, accuracy 0.1344818376068376
[!] Training Epoch 73, step 234 ==> loss 0.2500025939482909, accuracy 0.13396434294871795
[!] Training Epoch 74, step 234 ==> loss 0.2500025556128249, accuracy 0.13364716880341881
[!] Training Epoch 75, step 234 ==> loss 0.25000251931512457, accuracy 0.13364716880341881
[!] Training Epoch 76, step 234 ==> loss 0.25000248276270354, accuracy 0.13343015491452992
[!] Training Epoch 77, step 234 ==> loss 0.2500024491395706, accuracy 0.13319644764957264
[!] Training Epoch 78, step 234 ==> loss 0.2500024158985187, accuracy 0.13276241987179488
[!] Training Epoch 79, step 234 ==> loss 0.2500023839310703, accuracy 0.1328959668803419
[!] Training Epoch 80, step 234 ==> loss 0.25000235107209945, accuracy 0.13194444444444445
[!] Training Epoch 81, step 234 ==> loss 0.2500023188499304, accuracy 0.13192775106837606
[!] Training Epoch 82, step 234 ==> loss 0.25000229006649083, accuracy 0.13154380341880342
[!] Training Epoch 83, step 234 ==> loss 0.2500022609009702, accuracy 0.1314269497863248
[!] Training Epoch 84, step 234 ==> loss 0.2500022324996117, accuracy 0.1306590544871795
[!] Training Epoch 85, step 234 ==> loss 0.25000220282464963, accuracy 0.13075921474358973
[!] Training Epoch 86, step 234 ==> loss 0.2500021748053722, accuracy 0.13067574786324787
[!] Training Epoch 87, step 234 ==> loss 0.2500021490785811, accuracy 0.12987446581196582
[!] Training Epoch 88, step 234 ==> loss 0.2500021218234657, accuracy 0.12984107905982906
[!] Training Epoch 89, step 234 ==> loss 0.2500020982618006, accuracy 0.12957398504273504
[!] Training Epoch 90, step 234 ==> loss 0.25000207202556807, accuracy 0.12908987713675213
[!] Training Epoch 91, step 234 ==> loss 0.2500020501195875, accuracy 0.1291232638888889
[!] Training Epoch 92, step 234 ==> loss 0.25000202311919284, accuracy 0.12908987713675213
[!] Training Epoch 93, step 234 ==> loss 0.25000200235945547, accuracy 0.12892294337606838
[!] Training Epoch 94, step 234 ==> loss 0.25000197765154714, accuracy 0.1285556891025641
[!] Training Epoch 95, step 234 ==> loss 0.25000195727389085, accuracy 0.12808827457264957
[!] Training Epoch 96, step 234 ==> loss 0.2500019352405499, accuracy 0.12810496794871795
[!] Training Epoch 97, step 234 ==> loss 0.25000191409873146, accuracy 0.12768763354700854
[!] Training Epoch 98, step 234 ==> loss 0.2500018910465077, accuracy 0.1271534455128205
[!] Training Epoch 99, step 234 ==> loss 0.25000187003204966, accuracy 0.12735376602564102
[!] Training Epoch 100, step 234 ==> loss 0.2500018523289607, accuracy 0.1268863514957265
[!] Training Epoch 101, step 234 ==> loss 0.2500018327154665, accuracy 0.12725360576923078
[!] Training Epoch 102, step 234 ==> loss 0.2500018145029361, accuracy 0.12665264423076922
[!] Training Epoch 103, step 234 ==> loss 0.25000179297903663, accuracy 0.12661925747863248
[!] Training Epoch 104, step 234 ==> loss 0.25000177412970453, accuracy 0.1264523237179487
[!] Training Epoch 105, step 234 ==> loss 0.2500017557898138, accuracy 0.12595152243589744
[!] Training Epoch 106, step 234 ==> loss 0.25000173770464384, accuracy 0.1257011217948718
[!] Training Epoch 107, step 234 ==> loss 0.25000172140251875, accuracy 0.12571781517094016
[!] Training Epoch 108, step 234 ==> loss 0.2500017063739972, accuracy 0.12533386752136752
[!] Training Epoch 109, step 234 ==> loss 0.25000168854354793, accuracy 0.12494991987179487
[!] Training Epoch 110, step 234 ==> loss 0.2500016721140625, accuracy 0.1246494391025641
[!] Training Epoch 111, step 234 ==> loss 0.25000165581193745, accuracy 0.1247162126068376
[!] Training Epoch 112, step 234 ==> loss 0.25000163989189345, accuracy 0.12443242521367522
[!] Training Epoch 113, step 234 ==> loss 0.2500016261369754, accuracy 0.1242321047008547
[!] Training Epoch 114, step 234 ==> loss 0.25000160932540894, accuracy 0.12421541132478632
[!] Training Epoch 115, step 234 ==> loss 0.25000159416952705, accuracy 0.12401509081196581
[!] Training Epoch 116, step 234 ==> loss 0.25000157977780724, accuracy 0.12378138354700854
[!] Training Epoch 117, step 234 ==> loss 0.25000156602288925, accuracy 0.12354767628205128
[!] Training Epoch 118, step 234 ==> loss 0.2500015508670073, accuracy 0.12349759615384616
[!] Training Epoch 119, step 234 ==> loss 0.2500015371120893, accuracy 0.12344751602564102
[!] Training Epoch 120, step 234 ==> loss 0.25000152055524355, accuracy 0.1232638888888889
[!] Training Epoch 121, step 234 ==> loss 0.25000150832864976, accuracy 0.12343082264957266
[!] Training Epoch 122, step 234 ==> loss 0.2500014969935784, accuracy 0.123046875
[!] Training Epoch 123, step 234 ==> loss 0.25000148171033615, accuracy 0.12319711538461539
[!] Training Epoch 124, step 234 ==> loss 0.25000147101206655, accuracy 0.12291332799145299
[!] Training Epoch 125, step 234 ==> loss 0.2500014568750675, accuracy 0.12264623397435898
[!] Training Epoch 126, step 234 ==> loss 0.25000144286542875, accuracy 0.12289663461538461
[!] Training Epoch 127, step 234 ==> loss 0.2500014342049248, accuracy 0.12272970085470085
[!] Training Epoch 128, step 234 ==> loss 0.25000141904904294, accuracy 0.1228298611111111
[!] Training Epoch 129, step 234 ==> loss 0.25000140618564737, accuracy 0.12274639423076923
[!] Training Epoch 130, step 234 ==> loss 0.2500013965062606, accuracy 0.12237913995726496
[!] Training Epoch 131, step 234 ==> loss 0.2500013840249461, accuracy 0.12232905982905982
[!] Training Epoch 132, step 234 ==> loss 0.25000137396347827, accuracy 0.12229567307692307
[!] Training Epoch 133, step 234 ==> loss 0.25000136301048803, accuracy 0.12157785790598291
[!] Training Epoch 134, step 234 ==> loss 0.25000135205749774, accuracy 0.12216212606837606
[!] Training Epoch 135, step 234 ==> loss 0.25000134110450745, accuracy 0.12151108440170941
[!] Training Epoch 136, step 234 ==> loss 0.25000132951471543, accuracy 0.12191172542735043
[!] Training Epoch 137, step 234 ==> loss 0.2500013209815718, accuracy 0.12154447115384616
[!] Training Epoch 138, step 234 ==> loss 0.25000131002858156, accuracy 0.12104366987179487
[!] Training Epoch 139, step 234 ==> loss 0.2500013002218344, accuracy 0.12089342948717949
[!] Training Epoch 140, step 234 ==> loss 0.2500012907971684, accuracy 0.12094350961538461
[!] Training Epoch 141, step 234 ==> loss 0.2500012789526556, accuracy 0.12099358974358974
[!] Training Epoch 142, step 234 ==> loss 0.2500012688911878, accuracy 0.12094350961538461
[!] Training Epoch 143, step 234 ==> loss 0.250001260994846, accuracy 0.12042601495726496
[!] Training Epoch 144, step 234 ==> loss 0.25000125131545925, accuracy 0.12052617521367522
[!] Training Epoch 145, step 234 ==> loss 0.25000124036246896, accuracy 0.12059294871794872
[!] Training Epoch 146, step 234 ==> loss 0.25000123373973065, accuracy 0.1201923076923077
[!] Training Epoch 147, step 234 ==> loss 0.2500012241877042, accuracy 0.11994190705128205
[!] Training Epoch 148, step 234 ==> loss 0.25000121412623644, accuracy 0.12002537393162394
[!] Training Epoch 149, step 234 ==> loss 0.25000120584781355, accuracy 0.11999198717948718
[!] Training Epoch 150, step 234 ==> loss 0.25000119655050784, accuracy 0.11939102564102565
[!] Test batch 2 ==> loss 16.40234375, accuracy 0.1171875
[!] Test batch 3 ==> loss 13.66796875, accuracy 0.10546875
[!] Test batch 4 ==> loss 16.42578125, accuracy 0.11197916666666667
[!] Test batch 5 ==> loss 16.39453125, accuracy 0.1162109375
[!] Test batch 6 ==> loss 16.62109375, accuracy 0.11640625
[!] Test batch 7 ==> loss 14.59765625, accuracy 0.11458333333333333
[!] Test batch 8 ==> loss 16.46875, accuracy 0.11439732142857142
[!] Test batch 9 ==> loss 15.4375, accuracy 0.11181640625
[!] Test batch 10 ==> loss 15.0859375, accuracy 0.11284722222222222
[!] Test batch 11 ==> loss 15.5234375, accuracy 0.116015625
[!] Test batch 12 ==> loss 18.05859375, accuracy 0.11576704545454546
[!] Test batch 13 ==> loss 15.8984375, accuracy 0.115234375
[!] Test batch 14 ==> loss 15.71484375, accuracy 0.11568509615384616
[!] Test batch 15 ==> loss 15.2890625, accuracy 0.11746651785714286
[!] Test batch 16 ==> loss 16.59375, accuracy 0.11536458333333334
[!] Test batch 17 ==> loss 14.66015625, accuracy 0.114501953125
[!] Test batch 18 ==> loss 14.9375, accuracy 0.11511948529411764
[!] Test batch 19 ==> loss 16.0390625, accuracy 0.115234375
[!] Test batch 20 ==> loss 16.984375, accuracy 0.11451480263157894
[!] Test batch 21 ==> loss 17.58984375, accuracy 0.1130859375
[!] Test batch 22 ==> loss 15.05859375, accuracy 0.11495535714285714
[!] Test batch 23 ==> loss 16.27734375, accuracy 0.11576704545454546
[!] Test batch 24 ==> loss 16.578125, accuracy 0.11565896739130435
[!] Test batch 25 ==> loss 15.8203125, accuracy 0.11588541666666667
[!] Test batch 26 ==> loss 16.703125, accuracy 0.11515625
[!] Test batch 27 ==> loss 18.46484375, accuracy 0.11358173076923077
[!] Test batch 28 ==> loss 17.3515625, accuracy 0.11284722222222222
[!] Test batch 29 ==> loss 18.015625, accuracy 0.11272321428571429
[!] Test batch 30 ==> loss 16.0, accuracy 0.1136853448275862
[!] Test batch 31 ==> loss 16.33984375, accuracy 0.1140625
[!] Test batch 32 ==> loss 15.43359375, accuracy 0.1141633064516129
[!] Test batch 33 ==> loss 14.91796875, accuracy 0.114501953125
[!] Test batch 34 ==> loss 16.32421875, accuracy 0.11446496212121213
[!] Test batch 35 ==> loss 17.3828125, accuracy 0.11477481617647059
[!] Test batch 36 ==> loss 18.1484375, accuracy 0.11506696428571428
[!] Test batch 37 ==> loss 17.11328125, accuracy 0.11458333333333333
[!] Test batch 38 ==> loss 15.10546875, accuracy 0.11560388513513513
[!] Test batch 39 ==> loss 16.265625, accuracy 0.11543996710526316
[!] Test batch 40 ==> loss 13.72265625, accuracy 0.11648637820512821
=================================
[+] Average test Loss ==> 16.1388
[+] Test accuracy ==> 11.65