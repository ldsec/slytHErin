[!] Training Epoch 1, step 100 ==> loss 0.9128661006689072, accuracy 0.70984375
[!] Training Epoch 1, step 200 ==> loss 0.608200983479619, accuracy 0.8098046875
[!] Training Epoch 2, step 100 ==> loss 0.21819035291671754, accuracy 0.93765625
[!] Training Epoch 2, step 200 ==> loss 0.20517855558544398, accuracy 0.9404296875
[!] Training Epoch 3, step 100 ==> loss 0.15269879430532454, accuracy 0.9547265625
[!] Training Epoch 3, step 200 ==> loss 0.1504681144654751, accuracy 0.95521484375
[!] Training Epoch 4, step 100 ==> loss 0.12048175767064094, accuracy 0.963203125
[!] Training Epoch 4, step 200 ==> loss 0.11725419219583273, accuracy 0.96537109375
[!] Training Epoch 5, step 100 ==> loss 0.09747113097459077, accuracy 0.971953125
[!] Training Epoch 5, step 200 ==> loss 0.09774903444573284, accuracy 0.9708984375
[!] Training Epoch 6, step 100 ==> loss 0.08392112750560045, accuracy 0.9754296875
[!] Training Epoch 6, step 200 ==> loss 0.08184702845290304, accuracy 0.9758984375
[!] Training Epoch 7, step 100 ==> loss 0.06793393846601248, accuracy 0.9801953125
[!] Training Epoch 7, step 200 ==> loss 0.07037375522777438, accuracy 0.97974609375
[!] Training Epoch 8, step 100 ==> loss 0.06018001636490226, accuracy 0.9831640625
[!] Training Epoch 8, step 200 ==> loss 0.06097583913244307, accuracy 0.98255859375
[!] Training Epoch 9, step 100 ==> loss 0.05461273033171892, accuracy 0.984921875
[!] Training Epoch 9, step 200 ==> loss 0.054014134532772005, accuracy 0.98447265625
[!] Training Epoch 10, step 100 ==> loss 0.04771909447386861, accuracy 0.987109375
[!] Training Epoch 10, step 200 ==> loss 0.04828927065245807, accuracy 0.98609375
[!] Test batch 2 ==> loss 0.03637078404426575, accuracy 0.9921875
[!] Test batch 3 ==> loss 0.06862571835517883, accuracy 0.982421875
[!] Test batch 4 ==> loss 0.08715297281742096, accuracy 0.98046875
[!] Test batch 5 ==> loss 0.025175686925649643, accuracy 0.9833984375
[!] Test batch 6 ==> loss 0.044027090072631836, accuracy 0.984375
[!] Test batch 7 ==> loss 0.10259241610765457, accuracy 0.9811197916666666
[!] Test batch 8 ==> loss 0.13743561506271362, accuracy 0.9793526785714286
[!] Test batch 9 ==> loss 0.06644894182682037, accuracy 0.9794921875
[!] Test batch 10 ==> loss 0.09377778321504593, accuracy 0.9787326388888888
[!] Test batch 11 ==> loss 0.1035148948431015, accuracy 0.978515625
[!] Test batch 12 ==> loss 0.0745788961648941, accuracy 0.9783380681818182
[!] Test batch 13 ==> loss 0.08469945192337036, accuracy 0.9778645833333334
[!] Test batch 14 ==> loss 0.08145440369844437, accuracy 0.9777644230769231
[!] Test batch 15 ==> loss 0.10749972611665726, accuracy 0.9771205357142857
[!] Test batch 16 ==> loss 0.05949271470308304, accuracy 0.9776041666666667
[!] Test batch 17 ==> loss 0.12384942919015884, accuracy 0.9765625
[!] Test batch 18 ==> loss 0.09266543388366699, accuracy 0.9758731617647058
[!] Test batch 19 ==> loss 0.07342221587896347, accuracy 0.9765625
[!] Test batch 20 ==> loss 0.11105719208717346, accuracy 0.9761513157894737
[!] Test batch 21 ==> loss 0.074956975877285, accuracy 0.976171875
[!] Test batch 22 ==> loss 0.056360822170972824, accuracy 0.9763764880952381
[!] Test batch 23 ==> loss 0.05913892015814781, accuracy 0.9765625
[!] Test batch 24 ==> loss 0.06019579619169235, accuracy 0.9765625
[!] Test batch 25 ==> loss 0.04271073266863823, accuracy 0.9767252604166666
[!] Test batch 26 ==> loss 0.11008328199386597, accuracy 0.97640625
[!] Test batch 27 ==> loss 0.14968472719192505, accuracy 0.9761117788461539
[!] Test batch 28 ==> loss 0.05446361377835274, accuracy 0.9767071759259259
[!] Test batch 29 ==> loss 0.06373641639947891, accuracy 0.9768415178571429
[!] Test batch 30 ==> loss 0.0395195409655571, accuracy 0.9772359913793104
[!] Test batch 31 ==> loss 0.12916778028011322, accuracy 0.9770833333333333
[!] Test batch 32 ==> loss 0.11876063048839569, accuracy 0.9768145161290323
[!] Test batch 33 ==> loss 0.08510136604309082, accuracy 0.9764404296875
[!] Test batch 34 ==> loss 0.04639163985848427, accuracy 0.9765625
[!] Test batch 35 ==> loss 0.11879677325487137, accuracy 0.9763327205882353
[!] Test batch 36 ==> loss 0.09157680720090866, accuracy 0.9762276785714286
[!] Test batch 37 ==> loss 0.08064762502908707, accuracy 0.9764539930555556
[!] Test batch 38 ==> loss 0.07670583575963974, accuracy 0.9764569256756757
[!] Test batch 39 ==> loss 0.09228348731994629, accuracy 0.9763569078947368
[!] Test batch 40 ==> loss 0.0414215549826622, accuracy 0.9765625
=================================
[+] Average test Loss ==> 0.0812
[+] Test accuracy ==> 97.66