[!] Training Epoch 1, step 3750 ==> loss 0.05970106007655462, accuracy 0.69655
[!] Training Epoch 2, step 3750 ==> loss 0.044677214473485945, accuracy 0.834
[!] Training Epoch 3, step 3750 ==> loss 0.041846558046340944, accuracy 0.8519833333333333
[!] Training Epoch 4, step 3750 ==> loss 0.04006841047008832, accuracy 0.8606333333333334
[!] Training Epoch 5, step 3750 ==> loss 0.03850099848608176, accuracy 0.8662833333333333
[!] Training Epoch 6, step 3750 ==> loss 0.036957597053050996, accuracy 0.8735166666666667
[!] Training Epoch 7, step 3750 ==> loss 0.035508903777350984, accuracy 0.8789833333333333
[!] Training Epoch 8, step 3750 ==> loss 0.03424653067762653, accuracy 0.8849166666666667
[!] Training Epoch 9, step 3750 ==> loss 0.033118856492141885, accuracy 0.8899166666666667
[!] Training Epoch 10, step 3750 ==> loss 0.03207530339981119, accuracy 0.8951166666666667
[!] Training Epoch 11, step 3750 ==> loss 0.03102964235966404, accuracy 0.9003
[!] Training Epoch 12, step 3750 ==> loss 0.029938784124702217, accuracy 0.90615
[!] Training Epoch 13, step 3750 ==> loss 0.028862066645175218, accuracy 0.9111333333333334
[!] Training Epoch 14, step 3750 ==> loss 0.027764999084671338, accuracy 0.9163666666666667
[!] Training Epoch 15, step 3750 ==> loss 0.026711038606613873, accuracy 0.9212833333333333
[!] Training Epoch 16, step 3750 ==> loss 0.02570292732367913, accuracy 0.9261
[!] Training Epoch 17, step 3750 ==> loss 0.0247719384410729, accuracy 0.9306833333333333
[!] Training Epoch 18, step 3750 ==> loss 0.023927360604951778, accuracy 0.9345833333333333
[!] Training Epoch 19, step 3750 ==> loss 0.023158800735572974, accuracy 0.9377666666666666
[!] Training Epoch 20, step 3750 ==> loss 0.022452650954946876, accuracy 0.9409
[!] Training Epoch 21, step 3750 ==> loss 0.021822812777385115, accuracy 0.9428333333333333
[!] Training Epoch 22, step 3750 ==> loss 0.021245094532767933, accuracy 0.94475
[!] Training Epoch 23, step 3750 ==> loss 0.020713011637081703, accuracy 0.9465333333333333
[!] Training Epoch 24, step 3750 ==> loss 0.020222786745429037, accuracy 0.9485
[!] Training Epoch 25, step 3750 ==> loss 0.019760071318224073, accuracy 0.94965
[!] Training Epoch 26, step 3750 ==> loss 0.01933586506942908, accuracy 0.9510166666666666
[!] Training Epoch 27, step 3750 ==> loss 0.01893850702345371, accuracy 0.9528666666666666
[!] Training Epoch 28, step 3750 ==> loss 0.01855963310835262, accuracy 0.9536333333333333
[!] Training Epoch 29, step 3750 ==> loss 0.018213072750344873, accuracy 0.9545166666666667
[!] Training Epoch 30, step 3750 ==> loss 0.017881273530920345, accuracy 0.9561666666666667
[!] Training Epoch 31, step 3750 ==> loss 0.017554903817921876, accuracy 0.95675
[!] Training Epoch 32, step 3750 ==> loss 0.01725733634593586, accuracy 0.95805
[!] Training Epoch 33, step 3750 ==> loss 0.0169698073250552, accuracy 0.95865
[!] Training Epoch 34, step 3750 ==> loss 0.01669256956651807, accuracy 0.9589833333333333
[!] Training Epoch 35, step 3750 ==> loss 0.016436598617831866, accuracy 0.9600333333333333
[!] Training Epoch 36, step 3750 ==> loss 0.016188340154414376, accuracy 0.9606
[!] Training Epoch 37, step 3750 ==> loss 0.01594408900104463, accuracy 0.96095
[!] Training Epoch 38, step 3750 ==> loss 0.015707996635263163, accuracy 0.9622
[!] Training Epoch 39, step 3750 ==> loss 0.01549368088717262, accuracy 0.9626833333333333
[!] Training Epoch 40, step 3750 ==> loss 0.015272865822414557, accuracy 0.9631666666666666
[!] Training Epoch 41, step 3750 ==> loss 0.015069496764987707, accuracy 0.9639333333333333
[!] Training Epoch 42, step 3750 ==> loss 0.014880133908862869, accuracy 0.9646833333333333
[!] Training Epoch 43, step 3750 ==> loss 0.014687866631150246, accuracy 0.9648333333333333
[!] Training Epoch 44, step 3750 ==> loss 0.014502073012416562, accuracy 0.96555
[!] Training Epoch 45, step 3750 ==> loss 0.014333978452843925, accuracy 0.96565
[!] Training Epoch 46, step 3750 ==> loss 0.014163152766724427, accuracy 0.9663666666666667
[!] Training Epoch 47, step 3750 ==> loss 0.014007896039883295, accuracy 0.9669333333333333
[!] Training Epoch 48, step 3750 ==> loss 0.013852859230277438, accuracy 0.9669666666666666
[!] Training Epoch 49, step 3750 ==> loss 0.01370204963038365, accuracy 0.9676166666666667
[!] Training Epoch 50, step 3750 ==> loss 0.013564629086107016, accuracy 0.9673666666666667
[!] Test batch 2 ==> loss 0.014994850382208824, accuracy 1.0
[!] Test batch 3 ==> loss 0.008169258013367653, accuracy 1.0
[!] Test batch 4 ==> loss 0.009971598163247108, accuracy 1.0
[!] Test batch 5 ==> loss 0.020064378157258034, accuracy 0.96875
[!] Test batch 6 ==> loss 0.01792759634554386, accuracy 0.9625
[!] Test batch 7 ==> loss 0.011672744527459145, accuracy 0.96875
[!] Test batch 8 ==> loss 0.009719972498714924, accuracy 0.9732142857142857
[!] Test batch 9 ==> loss 0.005648497026413679, accuracy 0.9765625
[!] Test batch 10 ==> loss 0.013306471519172192, accuracy 0.9791666666666666
[!] Test batch 11 ==> loss 0.01123477891087532, accuracy 0.975
[!] Test batch 12 ==> loss 0.014916598796844482, accuracy 0.9772727272727273
[!] Test batch 13 ==> loss 0.01354476623237133, accuracy 0.9791666666666666
[!] Test batch 14 ==> loss 0.018352841958403587, accuracy 0.9759615384615384
[!] Test batch 15 ==> loss 0.019340965896844864, accuracy 0.9732142857142857
[!] Test batch 16 ==> loss 0.005643411073833704, accuracy 0.975
[!] Test batch 17 ==> loss 0.013089766725897789, accuracy 0.97265625
[!] Test batch 18 ==> loss 0.015689702704548836, accuracy 0.9742647058823529
[!] Test batch 19 ==> loss 0.019814608618617058, accuracy 0.96875
[!] Test batch 20 ==> loss 0.009983468800783157, accuracy 0.9671052631578947
[!] Test batch 21 ==> loss 0.011363891884684563, accuracy 0.965625
[!] Test batch 22 ==> loss 0.008550391532480717, accuracy 0.9672619047619048
[!] Test batch 23 ==> loss 0.020707977935671806, accuracy 0.9630681818181818
[!] Test batch 24 ==> loss 0.009805118665099144, accuracy 0.9646739130434783
[!] Test batch 25 ==> loss 0.009041834622621536, accuracy 0.9661458333333334
[!] Test batch 26 ==> loss 0.019722897559404373, accuracy 0.965
[!] Test batch 27 ==> loss 0.012668979354202747, accuracy 0.9663461538461539
[!] Test batch 28 ==> loss 0.013258317485451698, accuracy 0.9675925925925926
[!] Test batch 29 ==> loss 0.012056355364620686, accuracy 0.9665178571428571
[!] Test batch 30 ==> loss 0.02236991561949253, accuracy 0.9633620689655172
[!] Test batch 31 ==> loss 0.007957382127642632, accuracy 0.9645833333333333
[!] Test batch 32 ==> loss 0.011641573160886765, accuracy 0.9657258064516129
[!] Test batch 33 ==> loss 0.013931984081864357, accuracy 0.966796875
[!] Test batch 34 ==> loss 0.008350629359483719, accuracy 0.9678030303030303
[!] Test batch 35 ==> loss 0.011423534713685513, accuracy 0.9669117647058824
[!] Test batch 36 ==> loss 0.01333919633179903, accuracy 0.9660714285714286
[!] Test batch 37 ==> loss 0.008950190618634224, accuracy 0.9670138888888888
[!] Test batch 38 ==> loss 0.01457560621201992, accuracy 0.9679054054054054
[!] Test batch 39 ==> loss 0.01832045242190361, accuracy 0.9671052631578947
[!] Test batch 40 ==> loss 0.0033410489559173584, accuracy 0.967948717948718
[!] Test batch 41 ==> loss 0.013436888344585896, accuracy 0.9671875
[!] Test batch 42 ==> loss 0.01375453919172287, accuracy 0.9664634146341463
[!] Test batch 43 ==> loss 0.015931058675050735, accuracy 0.9657738095238095
[!] Test batch 44 ==> loss 0.007845191285014153, accuracy 0.9665697674418605
[!] Test batch 45 ==> loss 0.015284215100109577, accuracy 0.9673295454545454
[!] Test batch 46 ==> loss 0.022125493735074997, accuracy 0.9652777777777778
[!] Test batch 47 ==> loss 0.015624277293682098, accuracy 0.9660326086956522
[!] Test batch 48 ==> loss 0.005413287319242954, accuracy 0.9667553191489362
[!] Test batch 49 ==> loss 0.011617308482527733, accuracy 0.9661458333333334
[!] Test batch 50 ==> loss 0.012863298878073692, accuracy 0.9655612244897959
[!] Test batch 51 ==> loss 0.020411577075719833, accuracy 0.96375
[!] Test batch 52 ==> loss 0.017708078026771545, accuracy 0.9632352941176471
[!] Test batch 53 ==> loss 0.012942636385560036, accuracy 0.9639423076923077
[!] Test batch 54 ==> loss 0.017439892515540123, accuracy 0.9634433962264151
[!] Test batch 55 ==> loss 0.012241391465067863, accuracy 0.9641203703703703
[!] Test batch 56 ==> loss 0.014561312273144722, accuracy 0.9636363636363636
[!] Test batch 57 ==> loss 0.018854642286896706, accuracy 0.9620535714285714
[!] Test batch 58 ==> loss 0.018442459404468536, accuracy 0.9616228070175439
[!] Test batch 59 ==> loss 0.01551047246903181, accuracy 0.9612068965517241
[!] Test batch 60 ==> loss 0.013456763699650764, accuracy 0.9608050847457628
[!] Test batch 61 ==> loss 0.019855637103319168, accuracy 0.9604166666666667
[!] Test batch 62 ==> loss 0.0058667357079684734, accuracy 0.9610655737704918
[!] Test batch 63 ==> loss 0.010649996809661388, accuracy 0.9616935483870968
[!] Test batch 64 ==> loss 0.01295347511768341, accuracy 0.9613095238095238
[!] Test batch 65 ==> loss 0.02331678569316864, accuracy 0.9599609375
[!] Test batch 66 ==> loss 0.011926630511879921, accuracy 0.9605769230769231
[!] Test batch 67 ==> loss 0.011428284458816051, accuracy 0.9611742424242424
[!] Test batch 68 ==> loss 0.02018466591835022, accuracy 0.960820895522388
[!] Test batch 69 ==> loss 0.013015012256801128, accuracy 0.9604779411764706
[!] Test batch 70 ==> loss 0.009439250454306602, accuracy 0.9610507246376812
[!] Test batch 71 ==> loss 0.017682557925581932, accuracy 0.9607142857142857
[!] Test batch 72 ==> loss 0.021292556077241898, accuracy 0.960387323943662
[!] Test batch 73 ==> loss 0.011074063368141651, accuracy 0.9600694444444444
[!] Test batch 74 ==> loss 0.010191199369728565, accuracy 0.9606164383561644
[!] Test batch 75 ==> loss 0.015346582047641277, accuracy 0.9611486486486487
[!] Test batch 76 ==> loss 0.019099269062280655, accuracy 0.9608333333333333
[!] Test batch 77 ==> loss 0.00747690862044692, accuracy 0.9613486842105263
[!] Test batch 78 ==> loss 0.014406776055693626, accuracy 0.9618506493506493
[!] Test batch 79 ==> loss 0.016616053879261017, accuracy 0.9615384615384616
[!] Test batch 80 ==> loss 0.010497010312974453, accuracy 0.9620253164556962
[!] Test batch 81 ==> loss 0.009888384491205215, accuracy 0.9625
[!] Test batch 82 ==> loss 0.009922990575432777, accuracy 0.9629629629629629
[!] Test batch 83 ==> loss 0.017813149839639664, accuracy 0.9626524390243902
[!] Test batch 84 ==> loss 0.012551508843898773, accuracy 0.9631024096385542
[!] Test batch 85 ==> loss 0.021796144545078278, accuracy 0.9627976190476191
[!] Test batch 86 ==> loss 0.01405159942805767, accuracy 0.9625
[!] Test batch 87 ==> loss 0.007155724801123142, accuracy 0.9629360465116279
[!] Test batch 88 ==> loss 0.008250236511230469, accuracy 0.9633620689655172
[!] Test batch 89 ==> loss 0.00791086070239544, accuracy 0.9637784090909091
[!] Test batch 90 ==> loss 0.008576647378504276, accuracy 0.964185393258427
[!] Test batch 91 ==> loss 0.011589975096285343, accuracy 0.9645833333333333
[!] Test batch 92 ==> loss 0.013328430242836475, accuracy 0.9649725274725275
[!] Test batch 93 ==> loss 0.01227106899023056, accuracy 0.9653532608695652
[!] Test batch 94 ==> loss 0.017808418720960617, accuracy 0.9650537634408602
[!] Test batch 95 ==> loss 0.014661269262433052, accuracy 0.9647606382978723
[!] Test batch 96 ==> loss 0.01002502255141735, accuracy 0.9651315789473685
[!] Test batch 97 ==> loss 0.009244758635759354, accuracy 0.9654947916666666
[!] Test batch 98 ==> loss 0.014530587010085583, accuracy 0.9652061855670103
[!] Test batch 99 ==> loss 0.016182398423552513, accuracy 0.9649234693877551
[!] Test batch 100 ==> loss 0.01639946922659874, accuracy 0.9652777777777778
[!] Test batch 101 ==> loss 0.010506084188818932, accuracy 0.965625
[!] Test batch 102 ==> loss 0.011523519642651081, accuracy 0.9659653465346535
[!] Test batch 103 ==> loss 0.012606190517544746, accuracy 0.9656862745098039
[!] Test batch 104 ==> loss 0.01815863884985447, accuracy 0.9654126213592233
[!] Test batch 105 ==> loss 0.014280599541962147, accuracy 0.9657451923076923
[!] Test batch 106 ==> loss 0.010052450001239777, accuracy 0.9660714285714286
[!] Test batch 107 ==> loss 0.01274075172841549, accuracy 0.9658018867924528
[!] Test batch 108 ==> loss 0.009783157147467136, accuracy 0.9661214953271028
[!] Test batch 109 ==> loss 0.010692805983126163, accuracy 0.9658564814814815
[!] Test batch 110 ==> loss 0.034349288791418076, accuracy 0.9644495412844036
[!] Test batch 111 ==> loss 0.005835032090544701, accuracy 0.9647727272727272
[!] Test batch 112 ==> loss 0.010434037074446678, accuracy 0.9650900900900901
[!] Test batch 113 ==> loss 0.009537691250443459, accuracy 0.9654017857142857
[!] Test batch 114 ==> loss 0.012352353893220425, accuracy 0.9651548672566371
[!] Test batch 115 ==> loss 0.01741470769047737, accuracy 0.9643640350877193
[!] Test batch 116 ==> loss 0.007586853113025427, accuracy 0.9646739130434783
[!] Test batch 117 ==> loss 0.00945567898452282, accuracy 0.9649784482758621
[!] Test batch 118 ==> loss 0.014332197606563568, accuracy 0.9647435897435898
[!] Test batch 119 ==> loss 0.013239813968539238, accuracy 0.9645127118644068
[!] Test batch 120 ==> loss 0.011700799688696861, accuracy 0.9648109243697479
[!] Test batch 121 ==> loss 0.012468823231756687, accuracy 0.9651041666666667
[!] Test batch 122 ==> loss 0.018758447840809822, accuracy 0.9648760330578512
[!] Test batch 123 ==> loss 0.01937566138803959, accuracy 0.9646516393442623
[!] Test batch 124 ==> loss 0.018948009237647057, accuracy 0.9649390243902439
[!] Test batch 125 ==> loss 0.013649861328303814, accuracy 0.9652217741935484
[!] Test batch 126 ==> loss 0.010912401601672173, accuracy 0.9655
[!] Test batch 127 ==> loss 0.010016968473792076, accuracy 0.9652777777777778
[!] Test batch 128 ==> loss 0.007182837463915348, accuracy 0.9655511811023622
[!] Test batch 129 ==> loss 0.012018313631415367, accuracy 0.9658203125
[!] Test batch 130 ==> loss 0.01706664264202118, accuracy 0.9651162790697675
[!] Test batch 131 ==> loss 0.007068300154060125, accuracy 0.9653846153846154
[!] Test batch 132 ==> loss 0.014515772461891174, accuracy 0.9656488549618321
[!] Test batch 133 ==> loss 0.013109606690704823, accuracy 0.9654356060606061
[!] Test batch 134 ==> loss 0.014872374944388866, accuracy 0.9652255639097744
[!] Test batch 135 ==> loss 0.018601838499307632, accuracy 0.965018656716418
[!] Test batch 136 ==> loss 0.013311302289366722, accuracy 0.9648148148148148
[!] Test batch 137 ==> loss 0.011716967448592186, accuracy 0.9650735294117647
[!] Test batch 138 ==> loss 0.01893400028347969, accuracy 0.9648722627737226
[!] Test batch 139 ==> loss 0.019738007336854935, accuracy 0.9637681159420289
[!] Test batch 140 ==> loss 0.008349163457751274, accuracy 0.9640287769784173
[!] Test batch 141 ==> loss 0.018132338300347328, accuracy 0.9638392857142857
[!] Test batch 142 ==> loss 0.008450170047581196, accuracy 0.964095744680851
[!] Test batch 143 ==> loss 0.010657599195837975, accuracy 0.9643485915492958
[!] Test batch 144 ==> loss 0.00961414072662592, accuracy 0.9645979020979021
[!] Test batch 145 ==> loss 0.006551596336066723, accuracy 0.96484375
[!] Test batch 146 ==> loss 0.015006199479103088, accuracy 0.9646551724137931
[!] Test batch 147 ==> loss 0.017311837524175644, accuracy 0.9644691780821918
[!] Test batch 148 ==> loss 0.009866850450634956, accuracy 0.9647108843537415
[!] Test batch 149 ==> loss 0.01618725247681141, accuracy 0.964527027027027
[!] Test batch 150 ==> loss 0.015190313570201397, accuracy 0.9643456375838926
[!] Test batch 151 ==> loss 0.006977833807468414, accuracy 0.9645833333333333
[!] Test batch 152 ==> loss 0.01389224547892809, accuracy 0.9644039735099338
[!] Test batch 153 ==> loss 0.018998172134160995, accuracy 0.9638157894736842
[!] Test batch 154 ==> loss 0.006171041168272495, accuracy 0.9640522875816994
[!] Test batch 155 ==> loss 0.015612552873790264, accuracy 0.9642857142857143
[!] Test batch 156 ==> loss 0.010619481094181538, accuracy 0.964516129032258
[!] Test batch 157 ==> loss 0.012588148936629295, accuracy 0.9647435897435898
[!] Test batch 158 ==> loss 0.006123263388872147, accuracy 0.964968152866242
[!] Test batch 159 ==> loss 0.015520867891609669, accuracy 0.9647943037974683
[!] Test batch 160 ==> loss 0.016051169484853745, accuracy 0.9650157232704403
[!] Test batch 161 ==> loss 0.013317422941327095, accuracy 0.96484375
[!] Test batch 162 ==> loss 0.010336051695048809, accuracy 0.9650621118012422
[!] Test batch 163 ==> loss 0.012258240953087807, accuracy 0.9652777777777778
[!] Test batch 164 ==> loss 0.011435193940997124, accuracy 0.9654907975460123
[!] Test batch 165 ==> loss 0.011033675633370876, accuracy 0.9657012195121951
[!] Test batch 166 ==> loss 0.012157375924289227, accuracy 0.9659090909090909
[!] Test batch 167 ==> loss 0.019885404035449028, accuracy 0.9653614457831325
[!] Test batch 168 ==> loss 0.01044158823788166, accuracy 0.9655688622754491
[!] Test batch 169 ==> loss 0.010954431258141994, accuracy 0.9654017857142857
[!] Test batch 170 ==> loss 0.008471343666315079, accuracy 0.9656065088757396
[!] Test batch 171 ==> loss 0.006279899273067713, accuracy 0.9658088235294118
[!] Test batch 172 ==> loss 0.011919310316443443, accuracy 0.9660087719298246
[!] Test batch 173 ==> loss 0.024594692513346672, accuracy 0.965843023255814
[!] Test batch 174 ==> loss 0.02615262009203434, accuracy 0.9649566473988439
[!] Test batch 175 ==> loss 0.017845632508397102, accuracy 0.9647988505747126
[!] Test batch 176 ==> loss 0.016220899298787117, accuracy 0.9646428571428571
[!] Test batch 177 ==> loss 0.01030288077890873, accuracy 0.96484375
[!] Test batch 178 ==> loss 0.014091216027736664, accuracy 0.9646892655367232
[!] Test batch 179 ==> loss 0.02651715651154518, accuracy 0.964185393258427
[!] Test batch 180 ==> loss 0.020684203132987022, accuracy 0.964036312849162
[!] Test batch 181 ==> loss 0.01382483821362257, accuracy 0.9642361111111111
[!] Test batch 182 ==> loss 0.018177520483732224, accuracy 0.9644337016574586
[!] Test batch 183 ==> loss 0.017181921750307083, accuracy 0.9642857142857143
[!] Test batch 184 ==> loss 0.02297838218510151, accuracy 0.9641393442622951
[!] Test batch 185 ==> loss 0.015077891759574413, accuracy 0.9639945652173914
[!] Test batch 186 ==> loss 0.012064564041793346, accuracy 0.9641891891891892
[!] Test batch 187 ==> loss 0.01204187236726284, accuracy 0.9643817204301075
[!] Test batch 188 ==> loss 0.01718500442802906, accuracy 0.9642379679144385
[!] Test batch 189 ==> loss 0.019949985668063164, accuracy 0.964095744680851
[!] Test batch 190 ==> loss 0.010413571260869503, accuracy 0.9642857142857143
[!] Test batch 191 ==> loss 0.01448738295584917, accuracy 0.9641447368421052
[!] Test batch 192 ==> loss 0.010675601661205292, accuracy 0.9643324607329843
[!] Test batch 193 ==> loss 0.014172394759953022, accuracy 0.9641927083333334
[!] Test batch 194 ==> loss 0.015760619193315506, accuracy 0.9637305699481865
[!] Test batch 195 ==> loss 0.016181115061044693, accuracy 0.9635953608247423
[!] Test batch 196 ==> loss 0.010865218006074429, accuracy 0.9637820512820513
[!] Test batch 197 ==> loss 0.012784041464328766, accuracy 0.9636479591836735
[!] Test batch 198 ==> loss 0.010364984162151814, accuracy 0.9638324873096447
[!] Test batch 199 ==> loss 0.016262872144579887, accuracy 0.9636994949494949
[!] Test batch 200 ==> loss 0.004680332262068987, accuracy 0.9638819095477387
[!] Test batch 201 ==> loss 0.005641454830765724, accuracy 0.9640625
[!] Test batch 202 ==> loss 0.011632170528173447, accuracy 0.9642412935323383
[!] Test batch 203 ==> loss 0.007654817309230566, accuracy 0.9644183168316832
[!] Test batch 204 ==> loss 0.010976864024996758, accuracy 0.9642857142857143
[!] Test batch 205 ==> loss 0.015617984347045422, accuracy 0.9644607843137255
[!] Test batch 206 ==> loss 0.01662876270711422, accuracy 0.964329268292683
[!] Test batch 207 ==> loss 0.010636885650455952, accuracy 0.964502427184466
[!] Test batch 208 ==> loss 0.012037726119160652, accuracy 0.9643719806763285
[!] Test batch 209 ==> loss 0.00960840005427599, accuracy 0.9645432692307693
[!] Test batch 210 ==> loss 0.00917595811188221, accuracy 0.9647129186602871
[!] Test batch 211 ==> loss 0.01157875545322895, accuracy 0.9648809523809524
[!] Test batch 212 ==> loss 0.007244610693305731, accuracy 0.965047393364929
[!] Test batch 213 ==> loss 0.012361464090645313, accuracy 0.9649174528301887
[!] Test batch 214 ==> loss 0.010050065815448761, accuracy 0.9650821596244131
[!] Test batch 215 ==> loss 0.00860943179577589, accuracy 0.9652453271028038
[!] Test batch 216 ==> loss 0.018021555617451668, accuracy 0.9651162790697675
[!] Test batch 217 ==> loss 0.011679359711706638, accuracy 0.9649884259259259
[!] Test batch 218 ==> loss 0.013759325258433819, accuracy 0.9648617511520737
[!] Test batch 219 ==> loss 0.012240717187523842, accuracy 0.9647362385321101
[!] Test batch 220 ==> loss 0.006457903888076544, accuracy 0.9648972602739726
[!] Test batch 221 ==> loss 0.009625066071748734, accuracy 0.9650568181818182
[!] Test batch 222 ==> loss 0.007985083386301994, accuracy 0.9652149321266968
[!] Test batch 223 ==> loss 0.015970494598150253, accuracy 0.9653716216216216
[!] Test batch 224 ==> loss 0.007271540351212025, accuracy 0.9655269058295964
[!] Test batch 225 ==> loss 0.02027312107384205, accuracy 0.9654017857142857
[!] Test batch 226 ==> loss 0.007165583781898022, accuracy 0.9655555555555555
[!] Test batch 227 ==> loss 0.026942342519760132, accuracy 0.9651548672566371
[!] Test batch 228 ==> loss 0.01191222108900547, accuracy 0.9653083700440529
[!] Test batch 229 ==> loss 0.0200269166380167, accuracy 0.9651864035087719
[!] Test batch 230 ==> loss 0.01411224901676178, accuracy 0.964792576419214
[!] Test batch 231 ==> loss 0.012507125735282898, accuracy 0.964945652173913
[!] Test batch 232 ==> loss 0.01286922674626112, accuracy 0.9648268398268398
[!] Test batch 233 ==> loss 0.023212959989905357, accuracy 0.9647090517241379
[!] Test batch 234 ==> loss 0.010233755223453045, accuracy 0.9648605150214592
[!] Test batch 235 ==> loss 0.009923553094267845, accuracy 0.9650106837606838
[!] Test batch 236 ==> loss 0.017232287675142288, accuracy 0.9651595744680851
[!] Test batch 237 ==> loss 0.009134704247117043, accuracy 0.9653072033898306
[!] Test batch 238 ==> loss 0.012975720688700676, accuracy 0.9651898734177216
[!] Test batch 239 ==> loss 0.00902298092842102, accuracy 0.9653361344537815
[!] Test batch 240 ==> loss 0.012969302013516426, accuracy 0.9654811715481172
[!] Test batch 241 ==> loss 0.012595916166901588, accuracy 0.965625
[!] Test batch 242 ==> loss 0.012287457473576069, accuracy 0.9657676348547718
[!] Test batch 243 ==> loss 0.020553406327962875, accuracy 0.9653925619834711
[!] Test batch 244 ==> loss 0.014242617413401604, accuracy 0.9652777777777778
[!] Test batch 245 ==> loss 0.012421702034771442, accuracy 0.9651639344262295
[!] Test batch 246 ==> loss 0.012939132750034332, accuracy 0.9650510204081633
[!] Test batch 247 ==> loss 0.01268002949655056, accuracy 0.9649390243902439
[!] Test batch 248 ==> loss 0.01071383710950613, accuracy 0.965080971659919
[!] Test batch 249 ==> loss 0.014306810684502125, accuracy 0.9649697580645161
[!] Test batch 250 ==> loss 0.007780864834785461, accuracy 0.9651104417670683
[!] Test batch 251 ==> loss 0.02004140429198742, accuracy 0.965
[!] Test batch 252 ==> loss 0.01871635392308235, accuracy 0.9648904382470119
[!] Test batch 253 ==> loss 0.020230036228895187, accuracy 0.964781746031746
[!] Test batch 254 ==> loss 0.008788526989519596, accuracy 0.9649209486166008
[!] Test batch 255 ==> loss 0.009190422482788563, accuracy 0.9650590551181102
[!] Test batch 256 ==> loss 0.009643512777984142, accuracy 0.9651960784313726
[!] Test batch 257 ==> loss 0.008865879848599434, accuracy 0.96533203125
[!] Test batch 258 ==> loss 0.010691581293940544, accuracy 0.9654669260700389
[!] Test batch 259 ==> loss 0.009787073358893394, accuracy 0.9656007751937985
[!] Test batch 260 ==> loss 0.014901265501976013, accuracy 0.965492277992278
[!] Test batch 261 ==> loss 0.01610468327999115, accuracy 0.965625
[!] Test batch 262 ==> loss 0.01026667095720768, accuracy 0.9655172413793104
[!] Test batch 263 ==> loss 0.013570917770266533, accuracy 0.9656488549618321
[!] Test batch 264 ==> loss 0.014683695510029793, accuracy 0.965541825095057
[!] Test batch 265 ==> loss 0.005603509489446878, accuracy 0.9656723484848485
[!] Test batch 266 ==> loss 0.009912404231727123, accuracy 0.9658018867924528
[!] Test batch 267 ==> loss 0.011447908356785774, accuracy 0.9659304511278195
[!] Test batch 268 ==> loss 0.013472196646034718, accuracy 0.9658239700374532
[!] Test batch 269 ==> loss 0.009064992889761925, accuracy 0.9659514925373134
[!] Test batch 270 ==> loss 0.015351725742220879, accuracy 0.9660780669144982
[!] Test batch 271 ==> loss 0.0059487163089215755, accuracy 0.9662037037037037
[!] Test batch 272 ==> loss 0.015328213572502136, accuracy 0.9660977859778598
[!] Test batch 273 ==> loss 0.016541488468647003, accuracy 0.9662224264705882
[!] Test batch 274 ==> loss 0.028351765125989914, accuracy 0.9656593406593407
[!] Test batch 275 ==> loss 0.012710655108094215, accuracy 0.9657846715328468
[!] Test batch 276 ==> loss 0.011573147028684616, accuracy 0.9659090909090909
[!] Test batch 277 ==> loss 0.013080577366054058, accuracy 0.9660326086956522
[!] Test batch 278 ==> loss 0.0103074936196208, accuracy 0.9661552346570397
[!] Test batch 279 ==> loss 0.017046961933374405, accuracy 0.9662769784172662
[!] Test batch 280 ==> loss 0.020338427275419235, accuracy 0.9663978494623656
[!] Test batch 281 ==> loss 0.006074431352317333, accuracy 0.9665178571428571
[!] Test batch 282 ==> loss 0.009154250845313072, accuracy 0.9666370106761566
[!] Test batch 283 ==> loss 0.01373354159295559, accuracy 0.9665336879432624
[!] Test batch 284 ==> loss 0.01983836106956005, accuracy 0.9664310954063604
[!] Test batch 285 ==> loss 0.009549078531563282, accuracy 0.9665492957746479
[!] Test batch 286 ==> loss 0.012029958888888359, accuracy 0.9666666666666667
[!] Test batch 287 ==> loss 0.008456232026219368, accuracy 0.9667832167832168
[!] Test batch 288 ==> loss 0.013369676657021046, accuracy 0.9668989547038328
[!] Test batch 289 ==> loss 0.01424155943095684, accuracy 0.966796875
[!] Test batch 290 ==> loss 0.017877247184515, accuracy 0.9666955017301038
[!] Test batch 291 ==> loss 0.01898575946688652, accuracy 0.9663793103448276
[!] Test batch 292 ==> loss 0.014491868205368519, accuracy 0.9664948453608248
[!] Test batch 293 ==> loss 0.011403992772102356, accuracy 0.9666095890410958
[!] Test batch 294 ==> loss 0.006861291825771332, accuracy 0.9667235494880546
[!] Test batch 295 ==> loss 0.01391554158180952, accuracy 0.966624149659864
[!] Test batch 296 ==> loss 0.009579500183463097, accuracy 0.9667372881355932
[!] Test batch 297 ==> loss 0.016090307384729385, accuracy 0.9666385135135135
[!] Test batch 298 ==> loss 0.007961617782711983, accuracy 0.9667508417508418
[!] Test batch 299 ==> loss 0.013110877946019173, accuracy 0.9666526845637584
[!] Test batch 300 ==> loss 0.010939335450530052, accuracy 0.9665551839464883
[!] Test batch 301 ==> loss 0.011511732824146748, accuracy 0.9666666666666667
[!] Test batch 302 ==> loss 0.01192655973136425, accuracy 0.9667774086378738
[!] Test batch 303 ==> loss 0.01890072599053383, accuracy 0.9666804635761589
[!] Test batch 304 ==> loss 0.008776609785854816, accuracy 0.9667904290429042
[!] Test batch 305 ==> loss 0.008025528863072395, accuracy 0.9668996710526315
[!] Test batch 306 ==> loss 0.009594209492206573, accuracy 0.9670081967213114
[!] Test batch 307 ==> loss 0.01377893052995205, accuracy 0.9671160130718954
[!] Test batch 308 ==> loss 0.022181686013936996, accuracy 0.9668159609120521
[!] Test batch 309 ==> loss 0.009344159625470638, accuracy 0.9669237012987013
[!] Test batch 310 ==> loss 0.010777194052934647, accuracy 0.9668284789644013
[!] Test batch 311 ==> loss 0.011219963431358337, accuracy 0.9669354838709677
[!] Test batch 312 ==> loss 0.01340579055249691, accuracy 0.9666398713826366
[!] Test batch 313 ==> loss 0.020735060796141624, accuracy 0.9665464743589743
[!] Test batch 314 ==> loss 0.023224540054798126, accuracy 0.9664536741214057
[!] Test batch 315 ==> loss 0.009916300885379314, accuracy 0.9665605095541401
[!] Test batch 316 ==> loss 0.019693007692694664, accuracy 0.966468253968254
[!] Test batch 317 ==> loss 0.01977628655731678, accuracy 0.966376582278481
[!] Test batch 318 ==> loss 0.00956533569842577, accuracy 0.9664826498422713
[!] Test batch 319 ==> loss 0.01899736374616623, accuracy 0.9661949685534591
[!] Test batch 320 ==> loss 0.01827625185251236, accuracy 0.9661050156739812
[!] Test batch 321 ==> loss 0.01138758473098278, accuracy 0.9662109375
[!] Test batch 322 ==> loss 0.015800416469573975, accuracy 0.966316199376947
[!] Test batch 323 ==> loss 0.008961259387433529, accuracy 0.9664208074534162
[!] Test batch 324 ==> loss 0.010596787557005882, accuracy 0.9665247678018576
[!] Test batch 325 ==> loss 0.004833371378481388, accuracy 0.9666280864197531
[!] Test batch 326 ==> loss 0.014510979875922203, accuracy 0.9667307692307693
[!] Test batch 327 ==> loss 0.004859087057411671, accuracy 0.9668328220858896
[!] Test batch 328 ==> loss 0.00983709841966629, accuracy 0.966743119266055
[!] Test batch 329 ==> loss 0.012376895174384117, accuracy 0.9666539634146342
[!] Test batch 330 ==> loss 0.019580818712711334, accuracy 0.9663753799392097
[!] Test batch 331 ==> loss 0.004516169894486666, accuracy 0.9664772727272727
[!] Test batch 332 ==> loss 0.011558410711586475, accuracy 0.9665785498489426
[!] Test batch 333 ==> loss 0.0082309665158391, accuracy 0.9666792168674698
[!] Test batch 334 ==> loss 0.014986967667937279, accuracy 0.9667792792792793
[!] Test batch 335 ==> loss 0.014366254210472107, accuracy 0.9668787425149701
[!] Test batch 336 ==> loss 0.010824143886566162, accuracy 0.9669776119402985
[!] Test batch 337 ==> loss 0.008358951658010483, accuracy 0.9670758928571429
[!] Test batch 338 ==> loss 0.011239945888519287, accuracy 0.9671735905044511
[!] Test batch 339 ==> loss 0.007246165536344051, accuracy 0.9672707100591716
[!] Test batch 340 ==> loss 0.01482340693473816, accuracy 0.9673672566371682
[!] Test batch 341 ==> loss 0.01288816798478365, accuracy 0.9672794117647059
[!] Test batch 342 ==> loss 0.015016591176390648, accuracy 0.9671920821114369
[!] Test batch 343 ==> loss 0.021003328263759613, accuracy 0.9671052631578947
[!] Test batch 344 ==> loss 0.013269931077957153, accuracy 0.967201166180758
[!] Test batch 345 ==> loss 0.015514316968619823, accuracy 0.967296511627907
[!] Test batch 346 ==> loss 0.01841566525399685, accuracy 0.9672101449275362
[!] Test batch 347 ==> loss 0.015473389998078346, accuracy 0.9673049132947977
[!] Test batch 348 ==> loss 0.018348224461078644, accuracy 0.9672190201729106
[!] Test batch 349 ==> loss 0.021846067160367966, accuracy 0.9667744252873564
[!] Test batch 350 ==> loss 0.0073061129078269005, accuracy 0.9668696275071633
[!] Test batch 351 ==> loss 0.016276229172945023, accuracy 0.9667857142857142
[!] Test batch 352 ==> loss 0.009506957605481148, accuracy 0.9668803418803419
[!] Test batch 353 ==> loss 0.022213783115148544, accuracy 0.9666193181818182
[!] Test batch 354 ==> loss 0.01761927269399166, accuracy 0.9665368271954674
[!] Test batch 355 ==> loss 0.011412694118916988, accuracy 0.9666313559322034
[!] Test batch 356 ==> loss 0.007123688701540232, accuracy 0.9667253521126761
[!] Test batch 357 ==> loss 0.018863381817936897, accuracy 0.9664676966292135
[!] Test batch 358 ==> loss 0.017792990431189537, accuracy 0.9663865546218487
[!] Test batch 359 ==> loss 0.02020036242902279, accuracy 0.9663058659217877
[!] Test batch 360 ==> loss 0.013538071885704994, accuracy 0.966225626740947
[!] Test batch 361 ==> loss 0.01857617497444153, accuracy 0.9661458333333334
[!] Test batch 362 ==> loss 0.014796679839491844, accuracy 0.9660664819944599
[!] Test batch 363 ==> loss 0.017880555242300034, accuracy 0.9659875690607734
[!] Test batch 364 ==> loss 0.017426032572984695, accuracy 0.9659090909090909
[!] Test batch 365 ==> loss 0.01078721322119236, accuracy 0.9660027472527473
[!] Test batch 366 ==> loss 0.013291028328239918, accuracy 0.9659246575342466
[!] Test batch 367 ==> loss 0.011865404434502125, accuracy 0.9660177595628415
[!] Test batch 368 ==> loss 0.016011599451303482, accuracy 0.9661103542234333
[!] Test batch 369 ==> loss 0.01340568345040083, accuracy 0.9660326086956522
[!] Test batch 370 ==> loss 0.00918467529118061, accuracy 0.9661246612466124
[!] Test batch 371 ==> loss 0.008852137252688408, accuracy 0.9660472972972973
[!] Test batch 372 ==> loss 0.010564497672021389, accuracy 0.9661388140161725
[!] Test batch 373 ==> loss 0.015419025905430317, accuracy 0.9660618279569892
[!] Test batch 374 ==> loss 0.007689886726438999, accuracy 0.9661528150134048
[!] Test batch 375 ==> loss 0.02052534744143486, accuracy 0.9662433155080213
[!] Test batch 376 ==> loss 0.016099201515316963, accuracy 0.9661666666666666
[!] Test batch 377 ==> loss 0.007813764736056328, accuracy 0.9662566489361702
[!] Test batch 378 ==> loss 0.013019767589867115, accuracy 0.9663461538461539
[!] Test batch 379 ==> loss 0.014538183808326721, accuracy 0.9662698412698413
[!] Test batch 380 ==> loss 0.011349796317517757, accuracy 0.966358839050132
[!] Test batch 381 ==> loss 0.009430418722331524, accuracy 0.9664473684210526
[!] Test batch 382 ==> loss 0.012211575172841549, accuracy 0.9665354330708661
[!] Test batch 383 ==> loss 0.01564156636595726, accuracy 0.9664594240837696
[!] Test batch 384 ==> loss 0.008185681886970997, accuracy 0.9665469973890339
[!] Test batch 385 ==> loss 0.0162382572889328, accuracy 0.9666341145833334
[!] Test batch 386 ==> loss 0.015235918574035168, accuracy 0.9665584415584415
[!] Test batch 387 ==> loss 0.016371969133615494, accuracy 0.9664831606217616
[!] Test batch 388 ==> loss 0.00929875485599041, accuracy 0.9665697674418605
[!] Test batch 389 ==> loss 0.013272209092974663, accuracy 0.9666559278350515
[!] Test batch 390 ==> loss 0.011674530804157257, accuracy 0.9667416452442159
[!] Test batch 391 ==> loss 0.022822538390755653, accuracy 0.9666666666666667
[!] Test batch 392 ==> loss 0.011659390293061733, accuracy 0.9667519181585678
[!] Test batch 393 ==> loss 0.012736355885863304, accuracy 0.9668367346938775
[!] Test batch 394 ==> loss 0.017435133457183838, accuracy 0.9667620865139949
[!] Test batch 395 ==> loss 0.015607379376888275, accuracy 0.9668464467005076
[!] Test batch 396 ==> loss 0.019342128187417984, accuracy 0.9667721518987342
[!] Test batch 397 ==> loss 0.008509842678904533, accuracy 0.9668560606060606
[!] Test batch 398 ==> loss 0.009142311289906502, accuracy 0.9669395465994962
[!] Test batch 399 ==> loss 0.014240342192351818, accuracy 0.9670226130653267
[!] Test batch 400 ==> loss 0.009198536165058613, accuracy 0.9671052631578947
[!] Test batch 401 ==> loss 0.011472409591078758, accuracy 0.96703125
[!] Test batch 402 ==> loss 0.018037503585219383, accuracy 0.9668017456359103
[!] Test batch 403 ==> loss 0.015456676483154297, accuracy 0.966728855721393
[!] Test batch 404 ==> loss 0.013805896043777466, accuracy 0.9666563275434243
[!] Test batch 405 ==> loss 0.01666741445660591, accuracy 0.9665841584158416
[!] Test batch 406 ==> loss 0.013359236530959606, accuracy 0.9666666666666667
[!] Test batch 407 ==> loss 0.0116637097671628, accuracy 0.9667487684729064
[!] Test batch 408 ==> loss 0.006717585027217865, accuracy 0.9668304668304668
[!] Test batch 409 ==> loss 0.008305561728775501, accuracy 0.9669117647058824
[!] Test batch 410 ==> loss 0.01676911488175392, accuracy 0.9669926650366748
[!] Test batch 411 ==> loss 0.015675967559218407, accuracy 0.9669207317073171
[!] Test batch 412 ==> loss 0.012937906198203564, accuracy 0.9670012165450121
[!] Test batch 413 ==> loss 0.01002622488886118, accuracy 0.9670813106796117
[!] Test batch 414 ==> loss 0.013518271036446095, accuracy 0.9671610169491526
[!] Test batch 415 ==> loss 0.009657616727054119, accuracy 0.9670893719806763
[!] Test batch 416 ==> loss 0.00863832700997591, accuracy 0.9671686746987952
[!] Test batch 417 ==> loss 0.00970855075865984, accuracy 0.9672475961538461
[!] Test batch 418 ==> loss 0.011016188189387321, accuracy 0.967326139088729
[!] Test batch 419 ==> loss 0.004902402870357037, accuracy 0.9674043062200957
[!] Test batch 420 ==> loss 0.019955379888415337, accuracy 0.9671837708830548
[!] Test batch 421 ==> loss 0.013885527849197388, accuracy 0.9671130952380952
[!] Test batch 422 ==> loss 0.00934174470603466, accuracy 0.9671912114014252
[!] Test batch 423 ==> loss 0.011575601994991302, accuracy 0.9672689573459715
[!] Test batch 424 ==> loss 0.015291782096028328, accuracy 0.9673463356973995
[!] Test batch 425 ==> loss 0.010983851738274097, accuracy 0.9674233490566038
[!] Test batch 426 ==> loss 0.016755275428295135, accuracy 0.9673529411764706
[!] Test batch 427 ==> loss 0.01565862074494362, accuracy 0.9674295774647887
[!] Test batch 428 ==> loss 0.025624245405197144, accuracy 0.9672131147540983
[!] Test batch 429 ==> loss 0.00911159347742796, accuracy 0.9672897196261683
[!] Test batch 430 ==> loss 0.005210788920521736, accuracy 0.9673659673659674
[!] Test batch 431 ==> loss 0.009574562311172485, accuracy 0.9674418604651163
[!] Test batch 432 ==> loss 0.01857382245361805, accuracy 0.9672273781902552
[!] Test batch 433 ==> loss 0.0071386778727173805, accuracy 0.9673032407407407
[!] Test batch 434 ==> loss 0.018962671980261803, accuracy 0.9670900692840647
[!] Test batch 435 ==> loss 0.00752278883010149, accuracy 0.9671658986175116
[!] Test batch 436 ==> loss 0.010965411551296711, accuracy 0.9672413793103448
[!] Test batch 437 ==> loss 0.02024935558438301, accuracy 0.9670298165137615
[!] Test batch 438 ==> loss 0.011557480320334435, accuracy 0.9671052631578947
[!] Test batch 439 ==> loss 0.01109330914914608, accuracy 0.9671803652968036
[!] Test batch 440 ==> loss 0.016055580228567123, accuracy 0.967255125284738
[!] Test batch 441 ==> loss 0.009704865515232086, accuracy 0.9671875
[!] Test batch 442 ==> loss 0.015279705636203289, accuracy 0.9671201814058957
[!] Test batch 443 ==> loss 0.014274967834353447, accuracy 0.9670531674208145
[!] Test batch 444 ==> loss 0.018512114882469177, accuracy 0.9669864559819413
[!] Test batch 445 ==> loss 0.00909673236310482, accuracy 0.9670608108108109
[!] Test batch 446 ==> loss 0.007513955235481262, accuracy 0.9671348314606741
[!] Test batch 447 ==> loss 0.014050871133804321, accuracy 0.9670683856502242
[!] Test batch 448 ==> loss 0.011581212282180786, accuracy 0.9671420581655481
[!] Test batch 449 ==> loss 0.00842583179473877, accuracy 0.9672154017857143
[!] Test batch 450 ==> loss 0.00784838106483221, accuracy 0.9672884187082406
[!] Test batch 451 ==> loss 0.014418293721973896, accuracy 0.9673611111111111
[!] Test batch 452 ==> loss 0.008186387829482555, accuracy 0.9674334811529933
[!] Test batch 453 ==> loss 0.005911749787628651, accuracy 0.9675055309734514
[!] Test batch 454 ==> loss 0.014117226004600525, accuracy 0.967439293598234
[!] Test batch 455 ==> loss 0.023078788071870804, accuracy 0.9673733480176211
[!] Test batch 456 ==> loss 0.01683075539767742, accuracy 0.9673076923076923
[!] Test batch 457 ==> loss 0.011309846304357052, accuracy 0.9673793859649122
[!] Test batch 458 ==> loss 0.016281813383102417, accuracy 0.9673140043763676
[!] Test batch 459 ==> loss 0.005726830568164587, accuracy 0.9673853711790393
[!] Test batch 460 ==> loss 0.00926450826227665, accuracy 0.9674564270152506
[!] Test batch 461 ==> loss 0.011031907051801682, accuracy 0.9675271739130434
[!] Test batch 462 ==> loss 0.010777883231639862, accuracy 0.9675976138828634
[!] Test batch 463 ==> loss 0.009463331662118435, accuracy 0.9676677489177489
[!] Test batch 464 ==> loss 0.010865235701203346, accuracy 0.9677375809935205
[!] Test batch 465 ==> loss 0.008050660602748394, accuracy 0.9678071120689655
[!] Test batch 466 ==> loss 0.004886497277766466, accuracy 0.9678763440860215
[!] Test batch 467 ==> loss 0.013479272834956646, accuracy 0.9679452789699571
[!] Test batch 468 ==> loss 0.013294843025505543, accuracy 0.9680139186295503
[!] Test batch 469 ==> loss 0.008345024660229683, accuracy 0.9680822649572649
[!] Test batch 470 ==> loss 0.02264019474387169, accuracy 0.9678837953091685
[!] Test batch 471 ==> loss 0.007671576924622059, accuracy 0.9679521276595745
[!] Test batch 472 ==> loss 0.014320766553282738, accuracy 0.9678874734607219
[!] Test batch 473 ==> loss 0.02291686460375786, accuracy 0.9676906779661016
[!] Test batch 474 ==> loss 0.01652434468269348, accuracy 0.9676268498942917
[!] Test batch 475 ==> loss 0.007221878506243229, accuracy 0.9676951476793249
[!] Test batch 476 ==> loss 0.015290720388293266, accuracy 0.9677631578947369
[!] Test batch 477 ==> loss 0.01756538823246956, accuracy 0.9676995798319328
[!] Test batch 478 ==> loss 0.008846012875437737, accuracy 0.9677672955974843
[!] Test batch 479 ==> loss 0.013919854536652565, accuracy 0.9678347280334728
[!] Test batch 480 ==> loss 0.005302594508975744, accuracy 0.967901878914405
[!] Test batch 481 ==> loss 0.011911791749298573, accuracy 0.96796875
[!] Test batch 482 ==> loss 0.014943251386284828, accuracy 0.9679054054054054
[!] Test batch 483 ==> loss 0.010294240899384022, accuracy 0.9679719917012448
[!] Test batch 484 ==> loss 0.012525439262390137, accuracy 0.9680383022774327
[!] Test batch 485 ==> loss 0.01939045637845993, accuracy 0.9678460743801653
[!] Test batch 486 ==> loss 0.018301788717508316, accuracy 0.9677835051546392
[!] Test batch 487 ==> loss 0.00597086688503623, accuracy 0.9678497942386831
[!] Test batch 488 ==> loss 0.008342253044247627, accuracy 0.9679158110882957
[!] Test batch 489 ==> loss 0.00953493732959032, accuracy 0.9679815573770492
[!] Test batch 490 ==> loss 0.014715787954628468, accuracy 0.9679192229038854
[!] Test batch 491 ==> loss 0.01006296370178461, accuracy 0.967984693877551
[!] Test batch 492 ==> loss 0.015357163734734058, accuracy 0.9679226069246436
[!] Test batch 493 ==> loss 0.02105991542339325, accuracy 0.9678607723577236
[!] Test batch 494 ==> loss 0.009114161133766174, accuracy 0.9679259634888439
[!] Test batch 495 ==> loss 0.010160191915929317, accuracy 0.9679908906882592
[!] Test batch 496 ==> loss 0.011956848204135895, accuracy 0.9680555555555556
[!] Test batch 497 ==> loss 0.014506662264466286, accuracy 0.9681199596774194
[!] Test batch 498 ==> loss 0.01176946796476841, accuracy 0.9680583501006036
[!] Test batch 499 ==> loss 0.011597859673202038, accuracy 0.9681224899598394
[!] Test batch 500 ==> loss 0.020282937213778496, accuracy 0.968186372745491
[!] Test batch 501 ==> loss 0.017092261463403702, accuracy 0.96825
[!] Test batch 502 ==> loss 0.022116435691714287, accuracy 0.9680638722554891
[!] Test batch 503 ==> loss 0.011992905288934708, accuracy 0.9681274900398407
[!] Test batch 504 ==> loss 0.008954426273703575, accuracy 0.9681908548707754
[!] Test batch 505 ==> loss 0.008931310847401619, accuracy 0.9682539682539683
[!] Test batch 506 ==> loss 0.018887873739004135, accuracy 0.9683168316831683
[!] Test batch 507 ==> loss 0.009832086972892284, accuracy 0.9683794466403162
[!] Test batch 508 ==> loss 0.008335895836353302, accuracy 0.9684418145956607
[!] Test batch 509 ==> loss 0.01180814765393734, accuracy 0.968503937007874
[!] Test batch 510 ==> loss 0.008343437686562538, accuracy 0.9685658153241651
[!] Test batch 511 ==> loss 0.012833652086555958, accuracy 0.9685049019607843
[!] Test batch 512 ==> loss 0.00853089988231659, accuracy 0.9685665362035225
[!] Test batch 513 ==> loss 0.010609658434987068, accuracy 0.9686279296875
[!] Test batch 514 ==> loss 0.012593763880431652, accuracy 0.9685672514619883
[!] Test batch 515 ==> loss 0.013624307699501514, accuracy 0.9685068093385214
[!] Test batch 516 ==> loss 0.013481572270393372, accuracy 0.9684466019417476
[!] Test batch 517 ==> loss 0.011909174732863903, accuracy 0.9683866279069767
[!] Test batch 518 ==> loss 0.013030709698796272, accuracy 0.9684477756286267
[!] Test batch 519 ==> loss 0.017757028341293335, accuracy 0.9683880308880309
[!] Test batch 520 ==> loss 0.008353503420948982, accuracy 0.9684489402697495
[!] Test batch 521 ==> loss 0.014951100572943687, accuracy 0.9683894230769231
[!] Test batch 522 ==> loss 0.014607119373977184, accuracy 0.9684500959692899
[!] Test batch 523 ==> loss 0.010310021229088306, accuracy 0.9683908045977011
[!] Test batch 524 ==> loss 0.00806360598653555, accuracy 0.9684512428298279
[!] Test batch 525 ==> loss 0.012514087371528149, accuracy 0.9685114503816794
[!] Test batch 526 ==> loss 0.01431838609278202, accuracy 0.968452380952381
[!] Test batch 527 ==> loss 0.011194351129233837, accuracy 0.9685123574144486
[!] Test batch 528 ==> loss 0.016021091490983963, accuracy 0.9684535104364327
[!] Test batch 529 ==> loss 0.00846994761377573, accuracy 0.9685132575757576
[!] Test batch 530 ==> loss 0.009855725802481174, accuracy 0.9684546313799622
[!] Test batch 531 ==> loss 0.011616619303822517, accuracy 0.9685141509433962
[!] Test batch 532 ==> loss 0.017589569091796875, accuracy 0.9684557438794726
[!] Test batch 533 ==> loss 0.012847465462982655, accuracy 0.9683975563909775
[!] Test batch 534 ==> loss 0.00754571845754981, accuracy 0.9684568480300187
[!] Test batch 535 ==> loss 0.013385558500885963, accuracy 0.9683988764044944
[!] Test batch 536 ==> loss 0.011192670091986656, accuracy 0.9684579439252337
[!] Test batch 537 ==> loss 0.012107796967029572, accuracy 0.9685167910447762
[!] Test batch 538 ==> loss 0.018167898058891296, accuracy 0.9684590316573557
[!] Test batch 539 ==> loss 0.017676247283816338, accuracy 0.9684014869888475
[!] Test batch 540 ==> loss 0.012806353159248829, accuracy 0.9684601113172542
[!] Test batch 541 ==> loss 0.012759889476001263, accuracy 0.9685185185185186
[!] Test batch 542 ==> loss 0.016716526821255684, accuracy 0.9683456561922366
[!] Test batch 543 ==> loss 0.008251232095062733, accuracy 0.9684040590405905
[!] Test batch 544 ==> loss 0.009375710040330887, accuracy 0.9683471454880295
[!] Test batch 545 ==> loss 0.015505418181419373, accuracy 0.9684053308823529
[!] Test batch 546 ==> loss 0.011909480206668377, accuracy 0.968348623853211
[!] Test batch 547 ==> loss 0.0197859238833189, accuracy 0.9682921245421245
[!] Test batch 548 ==> loss 0.015784967690706253, accuracy 0.9683500914076782
[!] Test batch 549 ==> loss 0.01762760803103447, accuracy 0.9682937956204379
[!] Test batch 550 ==> loss 0.012833925895392895, accuracy 0.9682377049180327
[!] Test batch 551 ==> loss 0.013544397428631783, accuracy 0.9682954545454545
[!] Test batch 552 ==> loss 0.011673436500132084, accuracy 0.968352994555354
[!] Test batch 553 ==> loss 0.018382953479886055, accuracy 0.9684103260869565
[!] Test batch 554 ==> loss 0.016941053792834282, accuracy 0.968241410488246
[!] Test batch 555 ==> loss 0.009378191083669662, accuracy 0.9682987364620939
[!] Test batch 556 ==> loss 0.012975199148058891, accuracy 0.9682432432432433
[!] Test batch 557 ==> loss 0.015055912546813488, accuracy 0.9681879496402878
[!] Test batch 558 ==> loss 0.007046645041555166, accuracy 0.9682450628366248
[!] Test batch 559 ==> loss 0.01699230633676052, accuracy 0.9681899641577061
[!] Test batch 560 ==> loss 0.007513987831771374, accuracy 0.9682468694096601
[!] Test batch 561 ==> loss 0.019953761249780655, accuracy 0.9681919642857143
[!] Test batch 562 ==> loss 0.01678961142897606, accuracy 0.9680258467023173
[!] Test batch 563 ==> loss 0.01697370409965515, accuracy 0.9680827402135231
[!] Test batch 564 ==> loss 0.014980645850300789, accuracy 0.9680284191829485
[!] Test batch 565 ==> loss 0.02166183665394783, accuracy 0.967863475177305
[!] Test batch 566 ==> loss 0.004534583538770676, accuracy 0.9679203539823009
[!] Test batch 567 ==> loss 0.011388098821043968, accuracy 0.9678666077738516
[!] Test batch 568 ==> loss 0.009258565492928028, accuracy 0.9679232804232805
[!] Test batch 569 ==> loss 0.00811820663511753, accuracy 0.9679797535211268
[!] Test batch 570 ==> loss 0.006841718219220638, accuracy 0.968036028119508
[!] Test batch 571 ==> loss 0.010601833462715149, accuracy 0.9680921052631579
[!] Test batch 572 ==> loss 0.014086984097957611, accuracy 0.9681479859894921
[!] Test batch 573 ==> loss 0.009385327808558941, accuracy 0.9682036713286714
[!] Test batch 574 ==> loss 0.01687799021601677, accuracy 0.9681500872600349
[!] Test batch 575 ==> loss 0.016841445118188858, accuracy 0.9680966898954704
[!] Test batch 576 ==> loss 0.015060151927173138, accuracy 0.9681521739130434
[!] Test batch 577 ==> loss 0.008587257005274296, accuracy 0.9682074652777778
[!] Test batch 578 ==> loss 0.009539186954498291, accuracy 0.9682625649913345
[!] Test batch 579 ==> loss 0.0074654147028923035, accuracy 0.9683174740484429
[!] Test batch 580 ==> loss 0.013801038265228271, accuracy 0.9683721934369602
[!] Test batch 581 ==> loss 0.020269963890314102, accuracy 0.9683189655172414
[!] Test batch 582 ==> loss 0.006997568998485804, accuracy 0.9683734939759037
[!] Test batch 583 ==> loss 0.017354752868413925, accuracy 0.9683204467353952
[!] Test batch 584 ==> loss 0.005087632220238447, accuracy 0.9683747855917667
[!] Test batch 585 ==> loss 0.01892423816025257, accuracy 0.9683219178082192
[!] Test batch 586 ==> loss 0.011713986285030842, accuracy 0.9682692307692308
[!] Test batch 587 ==> loss 0.009199743159115314, accuracy 0.9683233788395904
[!] Test batch 588 ==> loss 0.01677299477159977, accuracy 0.968164395229983
[!] Test batch 589 ==> loss 0.011280183680355549, accuracy 0.968218537414966
[!] Test batch 590 ==> loss 0.012362761422991753, accuracy 0.9682724957555179
[!] Test batch 591 ==> loss 0.023750916123390198, accuracy 0.9682203389830508
[!] Test batch 592 ==> loss 0.019210364669561386, accuracy 0.9682741116751269
[!] Test batch 593 ==> loss 0.015759596601128578, accuracy 0.9683277027027027
[!] Test batch 594 ==> loss 0.01959070935845375, accuracy 0.968381112984823
[!] Test batch 595 ==> loss 0.015528945252299309, accuracy 0.9684343434343434
[!] Test batch 596 ==> loss 0.010771390981972218, accuracy 0.9684873949579832
[!] Test batch 597 ==> loss 0.021529104560613632, accuracy 0.9684354026845637
[!] Test batch 598 ==> loss 0.02068842016160488, accuracy 0.9683835845896147
[!] Test batch 599 ==> loss 0.016109036281704903, accuracy 0.9683319397993311
[!] Test batch 600 ==> loss 0.016449972987174988, accuracy 0.9682804674457429
[!] Test batch 601 ==> loss 0.01222306676208973, accuracy 0.9683333333333334
[!] Test batch 602 ==> loss 0.01104648131877184, accuracy 0.9683860232945092
[!] Test batch 603 ==> loss 0.022472569718956947, accuracy 0.9682308970099668
[!] Test batch 604 ==> loss 0.0045757535845041275, accuracy 0.9682835820895522
[!] Test batch 605 ==> loss 0.011994153261184692, accuracy 0.9682326158940397
[!] Test batch 606 ==> loss 0.008071094751358032, accuracy 0.9682851239669421
[!] Test batch 607 ==> loss 0.017082329839468002, accuracy 0.9681311881188119
[!] Test batch 608 ==> loss 0.013847338035702705, accuracy 0.9680807248764415
[!] Test batch 609 ==> loss 0.01588832587003708, accuracy 0.968030427631579
[!] Test batch 610 ==> loss 0.016524771228432655, accuracy 0.9679802955665024
[!] Test batch 611 ==> loss 0.007513140328228474, accuracy 0.9680327868852459
[!] Test batch 612 ==> loss 0.010059219785034657, accuracy 0.9680851063829787
[!] Test batch 613 ==> loss 0.019255194813013077, accuracy 0.9679330065359477
[!] Test batch 614 ==> loss 0.008466375060379505, accuracy 0.9679853181076672
[!] Test batch 615 ==> loss 0.012112473137676716, accuracy 0.9680374592833876
[!] Test batch 616 ==> loss 0.007271825335919857, accuracy 0.968089430894309
[!] Test batch 617 ==> loss 0.012280881404876709, accuracy 0.9681412337662337
[!] Test batch 618 ==> loss 0.020553218200802803, accuracy 0.9680915721231766
[!] Test batch 619 ==> loss 0.010871724225580692, accuracy 0.9681432038834952
[!] Test batch 620 ==> loss 0.014979571104049683, accuracy 0.9680936995153473
[!] Test batch 621 ==> loss 0.012693861499428749, accuracy 0.9681451612903226
[!] Test batch 622 ==> loss 0.02072053588926792, accuracy 0.9680958132045089
[!] Test batch 623 ==> loss 0.027567166835069656, accuracy 0.9679461414790996
[!] Test batch 624 ==> loss 0.007968738675117493, accuracy 0.9679975922953451
[!] Test batch 625 ==> loss 0.011489572934806347, accuracy 0.967948717948718
[!] Test batch 626 ==> loss 0.009513185359537601, accuracy 0.968
=================================
[+] Average test Loss ==> 0.0132
[+] Test accuracy ==> 96.80