{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYmdRutcpdeR"
      },
      "source": [
        "# Implementation of (simplified) CryptoNet for inference under homomorphic encryption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "prOXZ9RESeYD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "from activation import *\n",
        "from logger import Logger\n",
        "from dataHandler import DataHandler\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tunwxIS3XLgm"
      },
      "outputs": [],
      "source": [
        "class SimpleNet(nn.Module):\n",
        "  '''\n",
        "    Simpliefied network used in paper for inference https://www.microsoft.com/en-us/research/publication/cryptonets-applying-neural-networks-to-encrypted-data-with-high-throughput-and-accuracy/\n",
        "\n",
        "    Input size: 1x28x28 pixel\n",
        "    Pad: image is padded with 0s on left and top side --> 1x29x29\n",
        "    Conv1 --> 5x13x13\n",
        "    Pool1 --> 100x1x1 --> resized to 1x100x1\n",
        "    Pool2 --> 10x1x1 --> resized to a vector of len 10\n",
        "    \n",
        "  \n",
        "  \n",
        "  '''\n",
        "  \n",
        "  def __init__(self, batch_size : int, activation : str, sigmoid : str, init_method : str, verbose : bool):\n",
        "    super().__init__()\n",
        "    self.verbose = verbose\n",
        "    self.init_method = init_method\n",
        "    self.batch_size = batch_size\n",
        "    self.activation = activation\n",
        "    self.sigmoid = sigmoid\n",
        "\n",
        "    if activation == \"square\":\n",
        "      self.activation = torch.square\n",
        "    elif activation == \"relu\":\n",
        "      self.activation = nn.ReLU()\n",
        "    elif activation == \"relu_approx\":\n",
        "      self.activation = ReLUApprox()\n",
        "\n",
        "    if sigmoid == \"sigmoid\":\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "    elif sigmoid == \"approx\":\n",
        "      self.sigmoid = SigmoidApprox()\n",
        "    elif sigmoid == \"none\":\n",
        "      self.sigmoid = identity\n",
        "\n",
        "    self.pad = F.pad\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=5, stride=2)\n",
        "    self.pool1 = nn.Conv2d(in_channels=5, out_channels=100, kernel_size=13, stride=1000)\n",
        "    self.pool2 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(100,1), stride=1000)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pad(x, (1,0,1,0))\n",
        "    print(x.shape)\n",
        "    x = self.conv1(x)\n",
        "    print(x.shape)\n",
        "    x = self.activation(self.pool1(x))\n",
        "    print(x.shape)\n",
        "    x = x.reshape([self.batch_size,1,100,1]) #batch_size tensors in 1 channel, 100x1\n",
        "    x = self.activation(self.pool2(x))\n",
        "    print(x.shape)\n",
        "    x = self.sigmoid(x) ##needed for the probabilities --> i.e smaller loss, but ~ accuracy\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    print(x.shape)\n",
        "    return x\n",
        " \n",
        "  def weights_init(self, m):\n",
        "    for m in self.children():\n",
        "      if isinstance(m,nn.Conv2d):\n",
        "        if self.init_method == \"he\":\n",
        "          nn.init.kaiming_uniform_(m.weight, a=0, mode='fan_out', nonlinearity='relu')\n",
        "        elif self.init_method == \"xavier\":\n",
        "          nn.init.xavier_uniform_(m.weight, gain=math.sqrt(2))\n",
        "        #elif self.init_method == \"uniform\":\n",
        "        #  nn.init.uniform_(m.weight, -0.5, 0.5)\n",
        "        #elif self.init_method == \"norm\":\n",
        "        #  nn.init.normal_(m.weight, 0.0, 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sX-7JDDtHOo"
      },
      "source": [
        "Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3zxoMQRRsF1o"
      },
      "outputs": [],
      "source": [
        "dataHandler = DataHandler(dataset=\"MNIST\", batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OsCh6ldz9PN"
      },
      "source": [
        "Train and test pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tn61Mth4dz-l",
        "outputId": "917579cf-bbc8-4371-b1c3-a799e53d6153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n",
            "torch.Size([256, 1, 29, 29])\n",
            "torch.Size([256, 5, 13, 13])\n",
            "torch.Size([256, 100, 1, 1])\n",
            "torch.Size([256, 10, 1, 1])\n",
            "torch.Size([256, 10])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4e4654a87739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./logs/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"SimpleNet_{key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataHandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/lds_project/dnn-inference/dnn-inference/training/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(logger, model, dataHandler, num_epochs, lr, TPU)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0;31m#loss = Variable(loss, requires_grad = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTPU\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "##############################\n",
        "#                            #\n",
        "# TRAINING AND EVAL PIPELINE #\n",
        "#                            #\n",
        "##############################\n",
        "\n",
        "## TEST\n",
        "## init models \n",
        "#methods = [\"he\", \"xavier\", \"random\"] ##he init blows up values with square\n",
        "#methods = [\"xavier\",\"he\"]\n",
        "#activations = [\"relu_approx\",\"relu\"]\n",
        "#models = {}\n",
        "#sigmoid = True\n",
        "#for method in methods:\n",
        "#  for activation in activations:\n",
        "#    models[method+\"_\"+activation] = SimpleNet(batch_size=dataHandler.batch_size,\n",
        "#                                    activation=activation,\n",
        "#                                    init_method=method,\n",
        "#                                    verbose=False,\n",
        "#                                    sigmoid=sigmoid).to(device=device)\n",
        "## TEST\n",
        "\n",
        "models = {}\n",
        "#models[\"xavier_relu\"] = SimpleNet(batch_size=dataHandler.batch_size,\n",
        "#                                    activation=\"relu\",\n",
        "#                                    init_method=\"xavier\",\n",
        "#                                    verbose=False,\n",
        "#                                    sigmoid=True).to(device=device)\n",
        "#models[\"he_relu\"] = SimpleNet(batch_size=dataHandler.batch_size,\n",
        "#                                    activation=\"relu\",\n",
        "#                                    init_method=\"he\",\n",
        "#                                    verbose=False,\n",
        "#                                    sigmoid=True).to(device=device)\n",
        "\n",
        "## Most promising model. With approximated sigmoid we can increase accuracy\n",
        "## up to 96%, but it's not faithful to the original model, plus it is more complex\n",
        "models[\"xavier_relu_approx\"] = SimpleNet(batch_size=dataHandler.batch_size,\n",
        "                                    activation=\"relu_approx\",\n",
        "                                    init_method=\"xavier\",\n",
        "                                    sigmoid=\"none\",\n",
        "                                    verbose=False).to(device=device)\n",
        "\n",
        "#models[\"he_relu_approx\"] = SimpleNet(batch_size=dataHandler.batch_size,\n",
        "#                                    activation=\"relu_approx\",\n",
        "#                                    init_method=\"he\",\n",
        "#                                    verbose=False,\n",
        "#                                    sigmoid=False).to(device=device)\n",
        "\n",
        "scores = {}\n",
        "\n",
        "for key, model in models.items():\n",
        "  logger = Logger(\"./logs/\",f\"SimpleNet_{key}\")\n",
        "  model.apply(model.weights_init)\n",
        "  train(logger, model, dataHandler, num_epochs=400, lr=0.001)\n",
        "  loss, accuracy = eval(logger, model, dataHandler)\n",
        "  scores[key] = {\"loss\":loss, \"accuracy\":accuracy}\n",
        "  #torch.save(model, f\"./models/SimpleNet_{key}.pt\")\n",
        "\n",
        "\n",
        "for key, metrics in scores.items():\n",
        "  print(\"=====================================================================\")\n",
        "  print(f\"[+] Model with {key}: Avg test Loss ==> {metrics['loss']}, Accuracy ==> {metrics['accuracy']}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
