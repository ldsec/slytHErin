{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYmdRutcpdeR"
      },
      "source": [
        "# Implementation of (simplified) CryptoNet for inference under homomorphic encryption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "prOXZ9RESeYD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "from activation import relu_approx, sigmoid_approx\n",
        "from logger import Logger\n",
        "from dataHandler import DataHandler\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrxhF5Msda_u"
      },
      "source": [
        "CryptoNet from [Microsoft](https://www.microsoft.com/en-us/research/publication/cryptonets-applying-neural-networks-to-encrypted-data-with-high-throughput-and-accuracy/) ==> couldn't replicate results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "bGKsu0dNuGEH",
        "outputId": "9821ebf2-0c7d-42a4-dc53-39d3c11c03b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nclass ScaledAvgPool2d(nn.Module):\\n    \"\"\"Define the ScaledAvgPool layer, a.k.a the Sum Pool\"\"\"\\n    def __init__(self,kernel_size):\\n      super().__init__()\\n      self.kernel_size = kernel_size\\n      self.AvgPool = nn.AvgPool2d(kernel_size=self.kernel_size, stride=1, padding=int(math.ceil((kernel_size-1)/2)))\\n\\n    def forward(self,x):\\n      return (self.kernel_size**2)*self.AvgPool(x)\\n    \\n\\nclass CryptoNet(nn.Module):\\n  \"\"\"\\n    Original 9-layer network used during training\\n    CURRENTLY NOT WORKING\\n  \"\"\"\\n  def __init__(self, verbose):\\n    super().__init__()\\n    self.verbose = verbose\\n    self.pad = F.pad\\n    self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=5, stride=2)\\n    self.square1 = torch.square\\n    self.scaledAvgPool1 = ScaledAvgPool2d(kernel_size=3)\\n    self.conv2 = nn.Conv2d(in_channels=5, out_channels=50, kernel_size=5, stride=2)\\n    self.scaledAvgPool2 = ScaledAvgPool2d(kernel_size=3)\\n    self.fc1 = nn.Linear(in_features=1250, out_features=100)\\n    self.square2 = torch.square\\n    self.fc2 = nn.Linear(in_features=100, out_features=10)\\n    self.sigmoid = nn.Sigmoid()\\n\\n  def forward(self, x):\\n    x = self.pad(x, (1,0,1,0))\\n    if self.verbose:\\n      print(\"Start --> \",x.mean())\\n    x = self.conv1(x)\\n    if self.verbose:\\n      print(\"Conv1 --> \",x.mean())\\n    x = self.square1(x)\\n    if self.verbose:\\n      print(\"Sq --> \",x.mean())\\n    x = self.scaledAvgPool1(x)\\n    if self.verbose:\\n      print(\"Pool --> \",x.mean())\\n    x = self.conv2(x)\\n    if self.verbose:\\n      print(\"Conv2 --> \",x.mean())\\n    x = self.scaledAvgPool2(x)\\n    if self.verbose:\\n      print(\"Pool --> \",x.mean())\\n    ## Flatten\\n    x = x.reshape(x.shape[0], -1)\\n    x = self.fc1(x)\\n    if self.verbose:\\n      print(\"fc1 --> \",x.mean())\\n    x = self.square2(x)\\n    if self.verbose:\\n      print(\"Square --> \",x.mean())\\n    x = self.fc2(x)\\n    if self.verbose:\\n      print(\"fc2 --> \",x.mean())\\n    x = self.sigmoid(x)\\n    return x\\n\\n  def weights_init(self, m):\\n    \"\"\" Custom initilization to avoid square activation to blow up \"\"\"\\n    for m in self.children():\\n      if isinstance(m,nn.Conv2d):\\n        nn.init.kaiming_uniform_(m.weight, a=0, mode=\\'fan_in\\', nonlinearity=\\'relu\\')\\n      elif isinstance(m, nn.Linear):\\n        nn.init.uniform_(m.weight, 1e-4,1e-3)\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "class ScaledAvgPool2d(nn.Module):\n",
        "    \"\"\"Define the ScaledAvgPool layer, a.k.a the Sum Pool\"\"\"\n",
        "    def __init__(self,kernel_size):\n",
        "      super().__init__()\n",
        "      self.kernel_size = kernel_size\n",
        "      self.AvgPool = nn.AvgPool2d(kernel_size=self.kernel_size, stride=1, padding=int(math.ceil((kernel_size-1)/2)))\n",
        "\n",
        "    def forward(self,x):\n",
        "      return (self.kernel_size**2)*self.AvgPool(x)\n",
        "    \n",
        "\n",
        "class CryptoNet(nn.Module):\n",
        "  \"\"\"\n",
        "    Original 9-layer network used during training\n",
        "    CURRENTLY NOT WORKING\n",
        "  \"\"\"\n",
        "  def __init__(self, verbose):\n",
        "    super().__init__()\n",
        "    self.verbose = verbose\n",
        "    self.pad = F.pad\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=5, stride=2)\n",
        "    self.square1 = torch.square\n",
        "    self.scaledAvgPool1 = ScaledAvgPool2d(kernel_size=3)\n",
        "    self.conv2 = nn.Conv2d(in_channels=5, out_channels=50, kernel_size=5, stride=2)\n",
        "    self.scaledAvgPool2 = ScaledAvgPool2d(kernel_size=3)\n",
        "    self.fc1 = nn.Linear(in_features=1250, out_features=100)\n",
        "    self.square2 = torch.square\n",
        "    self.fc2 = nn.Linear(in_features=100, out_features=10)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pad(x, (1,0,1,0))\n",
        "    if self.verbose:\n",
        "      print(\"Start --> \",x.mean())\n",
        "    x = self.conv1(x)\n",
        "    if self.verbose:\n",
        "      print(\"Conv1 --> \",x.mean())\n",
        "    x = self.square1(x)\n",
        "    if self.verbose:\n",
        "      print(\"Sq --> \",x.mean())\n",
        "    x = self.scaledAvgPool1(x)\n",
        "    if self.verbose:\n",
        "      print(\"Pool --> \",x.mean())\n",
        "    x = self.conv2(x)\n",
        "    if self.verbose:\n",
        "      print(\"Conv2 --> \",x.mean())\n",
        "    x = self.scaledAvgPool2(x)\n",
        "    if self.verbose:\n",
        "      print(\"Pool --> \",x.mean())\n",
        "    ## Flatten\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    x = self.fc1(x)\n",
        "    if self.verbose:\n",
        "      print(\"fc1 --> \",x.mean())\n",
        "    x = self.square2(x)\n",
        "    if self.verbose:\n",
        "      print(\"Square --> \",x.mean())\n",
        "    x = self.fc2(x)\n",
        "    if self.verbose:\n",
        "      print(\"fc2 --> \",x.mean())\n",
        "    x = self.sigmoid(x)\n",
        "    return x\n",
        "\n",
        "  def weights_init(self, m):\n",
        "    \"\"\" Custom initilization to avoid square activation to blow up \"\"\"\n",
        "    for m in self.children():\n",
        "      if isinstance(m,nn.Conv2d):\n",
        "        nn.init.kaiming_uniform_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        nn.init.uniform_(m.weight, 1e-4,1e-3)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tunwxIS3XLgm"
      },
      "outputs": [],
      "source": [
        "class SimpleNet(nn.Module):\n",
        "  '''\n",
        "    Simpliefied network used in paper for inference https://www.microsoft.com/en-us/research/publication/cryptonets-applying-neural-networks-to-encrypted-data-with-high-throughput-and-accuracy/\n",
        "  '''\n",
        "  def __init__(self, batch_size : int, activation : str, init_method : str, verbose : bool, sigmoid : bool):\n",
        "    super().__init__()\n",
        "    self.verbose = verbose\n",
        "    self.init_method = init_method\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    if activation == \"square\":\n",
        "      self.activation = torch.square\n",
        "    elif activation == \"relu\":\n",
        "      self.activation = nn.ReLU()\n",
        "    elif activation == \"relu_approx\":\n",
        "      self.activation = relu_approx\n",
        "\n",
        "    if sigmoid:\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "    else:\n",
        "      self.sigmoid = sigmoid_approx\n",
        "\n",
        "    self.pad = F.pad\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=5, stride=2)\n",
        "    self.pool1 = nn.Conv2d(in_channels=5, out_channels=100, kernel_size=13, stride=1000)\n",
        "    self.pool2 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(100,1), stride=1000)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pad(x, (1,0,1,0))\n",
        "    x = self.conv1(x)\n",
        "    x = self.activation(self.pool1(x))\n",
        "    #print(x[0])\n",
        "    x = x.reshape([self.batch_size,1,100,1]) #batch_size tensors in 1 channel, 100x1\n",
        "    x = self.activation(self.pool2(x))\n",
        "    #print(x[0])\n",
        "    x = self.sigmoid(x) ##needed for the probabilities\n",
        "    x = x.reshape(x.shape[0], -1)\n",
        "    return x\n",
        " \n",
        "  def weights_init(self, m):\n",
        "    for m in self.children():\n",
        "      if isinstance(m,nn.Conv2d):\n",
        "        if self.init_method == \"he\":\n",
        "          nn.init.kaiming_uniform_(m.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
        "        elif self.init_method == \"xavier\":\n",
        "          nn.init.xavier_uniform_(m.weight, gain=math.sqrt(2))\n",
        "        elif self.init_method == \"uniform\":\n",
        "          nn.init.uniform_(m.weight, -0.5, 0.5)\n",
        "        elif self.init_method == \"norm\":\n",
        "          nn.init.normal_(m.weight, 0.0, 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sX-7JDDtHOo"
      },
      "source": [
        "Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3zxoMQRRsF1o"
      },
      "outputs": [],
      "source": [
        "dataHandler = DataHandler(dataset=\"MNIST\", batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OsCh6ldz9PN"
      },
      "source": [
        "Train and test pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tn61Mth4dz-l",
        "outputId": "917579cf-bbc8-4371-b1c3-a799e53d6153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[?] SimpleNet_xavier_relu_approx Epoch 1/100 Loss 0.1953\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 2/100 Loss 0.1952\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 3/100 Loss 0.1952\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 4/100 Loss 0.1952\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 5/100 Loss 0.1952\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 6/100 Loss 0.1952\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 7/100 Loss 0.1952\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 8/100 Loss 0.1952\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 9/100 Loss 0.1951\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 10/100 Loss 0.1938\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 11/100 Loss 0.1921\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 12/100 Loss 0.1910\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 13/100 Loss 0.1880\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 14/100 Loss 0.1837\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 15/100 Loss 0.1836\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 16/100 Loss 0.1777\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 17/100 Loss 0.1765\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 18/100 Loss 0.1746\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 19/100 Loss 0.1747\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 20/100 Loss 0.1752\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 21/100 Loss 0.1733\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 22/100 Loss 0.1736\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 23/100 Loss 0.1726\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 24/100 Loss 0.1710\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 25/100 Loss 0.1710\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 26/100 Loss 0.1721\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 27/100 Loss 0.1710\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 28/100 Loss 0.1723\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 29/100 Loss 0.1718\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 30/100 Loss 0.1713\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 31/100 Loss 0.1721\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 32/100 Loss 0.1714\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 33/100 Loss 0.1711\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 34/100 Loss 0.1701\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 35/100 Loss 0.1710\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 36/100 Loss 0.1699\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 37/100 Loss 0.1710\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 38/100 Loss 0.1727\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 39/100 Loss 0.1723\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 40/100 Loss 0.1721\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 41/100 Loss 0.1712\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 42/100 Loss 0.1709\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 43/100 Loss 0.1710\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 44/100 Loss 0.1703\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 45/100 Loss 0.1720\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 46/100 Loss 0.1706\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 47/100 Loss 0.1699\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 48/100 Loss 0.1707\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 49/100 Loss 0.1702\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 50/100 Loss 0.1700\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 51/100 Loss 0.1701\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 52/100 Loss 0.1696\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 53/100 Loss 0.1703\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 54/100 Loss 0.1695\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 55/100 Loss 0.1711\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 56/100 Loss 0.1705\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 57/100 Loss 0.1711\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 58/100 Loss 0.1707\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 59/100 Loss 0.1699\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 60/100 Loss 0.1687\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 61/100 Loss 0.1690\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 62/100 Loss 0.1700\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 63/100 Loss 0.1697\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 64/100 Loss 0.1701\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 65/100 Loss 0.1684\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 66/100 Loss 0.1701\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 67/100 Loss 0.1702\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 68/100 Loss 0.1696\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 69/100 Loss 0.1698\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 70/100 Loss 0.1694\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 71/100 Loss 0.1719\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 72/100 Loss 0.1709\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 73/100 Loss 0.1690\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 74/100 Loss 0.1703\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 75/100 Loss 0.1685\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 76/100 Loss 0.1690\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 77/100 Loss 0.1699\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 78/100 Loss 0.1692\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 79/100 Loss 0.1704\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 80/100 Loss 0.1696\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 81/100 Loss 0.1694\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 82/100 Loss 0.1689\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 83/100 Loss 0.1695\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 84/100 Loss 0.1702\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 85/100 Loss 0.1694\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 86/100 Loss 0.1707\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 87/100 Loss 0.1687\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 88/100 Loss 0.1688\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 89/100 Loss 0.1689\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 90/100 Loss 0.1697\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 91/100 Loss 0.1696\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 92/100 Loss 0.1717\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 93/100 Loss 0.1698\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 94/100 Loss 0.1686\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 95/100 Loss 0.1699\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 96/100 Loss 0.1691\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 97/100 Loss 0.1700\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 98/100 Loss 0.1689\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 99/100 Loss 0.1691\n",
            "[?] SimpleNet_xavier_relu_approx Epoch 100/100 Loss 0.1701\n",
            "[?] SimpleNet_xavier_square Epoch 1/100 Loss 0.2492\n",
            "[?] SimpleNet_xavier_square Epoch 2/100 Loss 0.2436\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ff27f7559ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./logs/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"SimpleNet_{key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataHandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/lds_project/dnn-inference/dnn-inference/training/utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(logger, model, dataHandler, num_epochs, TPU)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0;31m#loss = Variable(loss, requires_grad = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTPU\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "##############################\n",
        "#                            #\n",
        "# TRAINING AND EVAL PIPELINE #\n",
        "#                            #\n",
        "##############################\n",
        "\n",
        "## init models\n",
        "#methods = [\"he\", \"xavier\", \"random\"] ##he init blows up values with square\n",
        "methods = [\"xavier\",\"random\"]\n",
        "activations = [\"relu_approx\",\"square\"]#\"relu\"]\n",
        "models = {}\n",
        "sigmoid = False\n",
        "for method in methods:\n",
        "  for activation in activations:\n",
        "    models[method+\"_\"+activation] = SimpleNet(batch_size=dataHandler.batch_size,\n",
        "                                    activation=activation,\n",
        "                                    init_method=method,\n",
        "                                    verbose=False,\n",
        "                                    sigmoid=sigmoid).to(device=device)\n",
        "scores = {}\n",
        "\n",
        "## Testing of different stuff ==> result was best xavier+square\n",
        "for key, model in models.items():\n",
        "  logger = Logger(\"./logs/\",f\"SimpleNet_{key}\")\n",
        "  model.apply(model.weights_init)\n",
        "  train(logger, model, dataHandler, num_epochs=150)\n",
        "  loss, accuracy = eval(logger, model, dataHandler)\n",
        "  scores[key] = {\"loss\":loss, \"accuracy\":accuracy}\n",
        "  if sigmoid:\n",
        "    torch.save(model, f\"SimpleNet_{key}_sigmoid.pt\")\n",
        "  else:\n",
        "    torch.save(model, f\"SimpleNet_{key}_approx_sigmoid.pt\")\n",
        "\n",
        "## Best Model on 10 epochs\n",
        "#key = \"xavier_relu\"\n",
        "#model = models[key]\n",
        "#model.apply(model.weights_init)\n",
        "#train(key, model, dataHandler, num_epochs=150, TPU=False)\n",
        "#loss, accuracy = eval(key,model, dataHandler)\n",
        "#scores[key] = {\"loss\":loss, \"accuracy\":accuracy}\n",
        "#torch.save(model, f\"SimpleNet_{key}.pt\")\n",
        "\n",
        "for key, metrics in scores.items():\n",
        "  print(\"=====================================================================\")\n",
        "  print(f\"[+] Model with {key}: Avg test Loss ==> {metrics['loss']}, Accuracy ==> {metrics['accuracy']}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
