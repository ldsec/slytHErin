# -*- coding: utf-8 -*-
"""AlexNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H_YJAXxS_ALNqGzdv6PtDOLP2iUuSJpw

Training of AlexNet with simplified pooling on MNIST
"""

import torch
import torchvision
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from torchvision.transforms import ToTensor
from torchvision.datasets import MNIST
from torch.utils.data.dataloader import DataLoader
from torch.utils.data import random_split
from torchvision.utils import save_image
import torch.optim as optim
from torch.utils.data import random_split
import matplotlib.pyplot as plt
from matplotlib.lines import Line2D
import math

## interactive off
plt.ioff()
## setup torch enviro
torch.manual_seed(42)
torch.autograd.set_detect_anomaly(True)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(42)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

####################
#                  #
# MODEL DEFINITION #
#                  #
####################

class ScaledAvgPool2d(nn.Module):
    """Define the ScaledAvgPool layer, a.k.a the Sum Pool"""
    def __init__(self, kernel_size, stride, padding=0):
      super().__init__()
      self.kernel_size = kernel_size
      self.AvgPool = nn.AvgPool2d(kernel_size=self.kernel_size, stride=stride, padding=padding)

    def forward(self,x):
      return (self.kernel_size**2)*self.AvgPool(x)

class AlexNet(nn.Module):
  """ Simplified AlexNet with Sum Pooling """
  def __init__(self, verbose: bool):
    super().__init__()
    self.verbose = verbose
    ## input size for MNIST = 227
    self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, stride=4, padding=2)
    self.pool1 = ScaledAvgPool2d(kernel_size=3, stride=2)
    self.conv2 = nn.Conv2d(in_channels=64, out_channels=192, kernel_size=5, stride=1, padding=2)
    self.conv3 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, stride=1, padding=1)
    self.conv4 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)
    self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)
    self.pool2 = ScaledAvgPool2d(kernel_size=3, stride=1, padding=1)
    self.ReLU = nn.ReLU(inplace=True)
    self.classifier = nn.Sequential(
        nn.Dropout(p=0.5),
        nn.Linear(in_features= 9216, out_features= 4096),
        nn.ReLU(inplace=True),
        nn.Dropout(p=0.5),
        nn.Linear(in_features= 4096, out_features= 4096),
        nn.ReLU(inplace=True),
        nn.Linear(in_features= 4096, out_features= 10)
    )

    ## init weights
    nn.init.kaiming_uniform_(self.conv1.weight, a=0, mode='fan_in', nonlinearity='relu')
    nn.init.kaiming_uniform_(self.conv2.weight, a=0, mode='fan_in', nonlinearity='relu')
    nn.init.kaiming_uniform_(self.conv3.weight, a=0, mode='fan_in', nonlinearity='relu')
    nn.init.kaiming_uniform_(self.conv4.weight, a=0, mode='fan_in', nonlinearity='relu')
    nn.init.kaiming_uniform_(self.conv5.weight, a=0, mode='fan_in', nonlinearity='relu')
    i = 0
    for layer in self.classifier.children():
      if not isinstance(layer, nn.Dropout) and not isinstance(layer, nn.ReLU):
        if i < 2:
          nn.init.kaiming_uniform_(layer.weight, a=0, mode='fan_in', nonlinearity='relu')
          i += 1
        else:
          nn.init.xavier_uniform_(layer.weight, gain=math.sqrt(2))    
          i += 1
    

  def forward(self,x):
    x = self.ReLU(self.conv1(x))
    x = self.pool1(x)
    x = self.ReLU(self.conv2(x))
    x = self.pool1(x)
    x = self.ReLU(self.conv3(x))
    x = self.ReLU(self.conv4(x))
    x = self.ReLU(self.conv5(x))
    x = self.pool1(x)
    x = self.pool2(x)
    x = x.reshape(x.shape[0], -1)
    x = self.classifier(x)
    return x

#################
#               #
# DATA HANDLER  #
#               #
#################

class DataHandler():
  def __init__(self, dataset : str, batch_size : int):
    if dataset == "MNIST":
      self.batch_size = batch_size
      normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
      
      to_rgb = transforms.Lambda(lambda image: image.convert('RGB'))
      resize = transforms.Resize((227, 227))
      transform = transforms.Compose([resize, to_rgb, transforms.ToTensor(), normalize])

      train_ds = MNIST("data/", train=True, download=True, transform=transform)
      test_ds = MNIST("data/", train=False, download=True, transform=transform)

      self.train_dl = DataLoader(train_ds, batch_size = batch_size, shuffle=True, drop_last=True, num_workers=2, pin_memory=True)
      self.test_dl = DataLoader(test_ds, batch_size = batch_size, shuffle=True, drop_last=True, num_workers=2, pin_memory=True)

dataHandler = DataHandler("MNIST", 256)

##################
#                #
# TRAIN AND EVAL #
#                #
##################

## training params setup
learning_rate = 3e-4
total_step = len(dataHandler.train_dl)
criterion = nn.CrossEntropyLoss()

## DEBUG GRADS
def plot_grad_flow(named_parameters):
    ## From https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063
    ## Beware it's a little bit tricky to interpret results
    '''Plots the gradients flowing through different layers in the net during training.
    Can be used for checking for possible gradient vanishing / exploding problems.
    
    Usage: Plug this function in Trainer class after loss.backwards() as 
    "plot_grad_flow(self.model.named_parameters())" to visualize the gradient flow'''

    ave_grads = []
    max_grads = []
    layers = []
    for n, p in named_parameters:
        if(p.requires_grad) and ("bias" not in n):
            layers.append(n)
            ave_grads.append(p.grad.abs().mean())
            max_grads.append(p.grad.abs().max())
            print(f"Layer {n}, grad avg {p.grad.mean()}, data {p.data.mean()}")
    plt.bar(np.arange(len(max_grads)), max(max_grads), alpha=0.1, lw=1, color="c")
    plt.bar(np.arange(len(max_grads)), np.mean(ave_grads), alpha=0.1, lw=1, color="b")
    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color="k" )
    plt.xticks(range(0,len(ave_grads), 1), layers, rotation="vertical")
    plt.xlim(left=0, right=len(ave_grads))
    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions
    plt.xlabel("Layers")
    plt.ylabel("average gradient")
    plt.title("Gradient flow")
    plt.grid(True)
    plt.legend([Line2D([0], [0], color="c", lw=4),
                Line2D([0], [0], color="b", lw=4),
                Line2D([0], [0], color="k", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])
    
## PLOT HELPER
def plot_history(key, train, history):
  """ 
    Plot loss and accuracy history during model run
    Input:
          key : str => name of the model
          train : bool => training 1 or test 0
          history : dict{str : list of floats}
  """
  if train:
    when = "train"
  else:
    when = "test"
  fig, ax = plt.subplots( 1, 2, figsize = (12,4) )
  ax[0].plot(history['loss'], label = when+"----"+key)
  ax[0].set_title( "Loss" )
  ax[0].set_xlabel( "Epochs" )
  ax[0].set_ylabel( "Loss" )
  ax[0].grid( True )
  ax[0].legend()

  ax[1].plot(history['accuracy'], label = when+"----"+key)
  ax[1].set_title( "Accuracy" )
  ax[1].set_xlabel( "Epochs" )
  ax[1].set_ylabel( "Accuracy" )
  ax[1].grid( True )
  ax[1].legend()

  plt.savefig(f"key_{when}.png")

## TRAIN
def train(key, model, dataHandler, num_epochs, TPU=False):
  num_epochs = num_epochs
  model.train()
  #optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)
  optimizer = optim.Adam(model.parameters(), lr=learning_rate)

  trainHistory = {}
  trainHistory['loss'] = []
  trainHistory['accuracy'] = []

  for epoch in range(num_epochs):
    epoch_loss = 0
    epoch_accuracy = 0
    num_correct = 0
    num_samples = 0
    for i, (data, labels) in enumerate(dataHandler.train_dl):
      data = data.to(device=device)
      labels = labels.to(device=device)
      #labels = labels.to(torch.float32)

      optimizer.zero_grad()
      predictions = model(data)
      loss = criterion(predictions, labels)
      loss.backward()
      
      if model.verbose:
        print(f"[?] Step {i+1} Epoch {epoch+1}")
        plot_grad_flow(model.named_parameters())
      
      if not TPU:
        optimizer.step()
      else:
        xm.optimizer_step(optimizer, barrier=True) ## if TPU 
      
      _, predicted_labels = predictions.max(1)
      num_correct += (predicted_labels == labels).sum().item()
      num_samples += predicted_labels.size(0)
      
      epoch_accuracy += num_correct/num_samples
      epoch_loss += loss.item()

      if (i+1) % 100 == 0:
        print("=====================================================================================================================")
        print ('[!] Train Epoch [{}/{}], Step [{}/{}] ==> Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))
      
    trainHistory['loss'].append(epoch_loss/len(dataHandler.train_dl))
    trainHistory['accuracy'].append(epoch_accuracy/len(dataHandler.train_dl))
    
  plot_history(key, True, trainHistory)


## EVAL 
def eval(key, model, dataHandler):
  num_correct = 0
  num_samples = 0

  model.eval()
  testHistory = {}
  testHistory['loss'] = []
  testHistory['accuracy'] = []
  test_loss = 0
  accuracy = 0
  with torch.no_grad():
    for _, (data,labels) in enumerate(dataHandler.test_dl):
        data = data.to(device="cpu")
        labels = labels.to(device="cpu")
        ## Forward Pass
        predictions = model(data)
        loss = criterion(predictions, labels).item()
        test_loss += loss
        _, predicted_labels = predictions.max(1)
        num_correct += (predicted_labels == labels).sum().item()
        num_samples += predicted_labels.size(0)
        testHistory['loss'].append(loss)
        testHistory['accuracy'].append(float(num_correct) / float(num_samples))
  
    accuracy = float(num_correct) / float(num_samples)
    test_loss = test_loss/len(dataHandler.test_dl)
    print("=============================")
    print(f"Average test Loss ==> {test_loss}")
    print(f"Test accuracy ==> {float(num_correct) / float(num_samples) * 100:.2f}")

    plot_history(key, False, testHistory)

  return test_loss, accuracy

model = AlexNet(False).to(device=device)
train("alex", model, dataHandler, 1, TPU=False)
eval("alex", model, dataHandler)
torch.save(model, "AlexNet.pt")